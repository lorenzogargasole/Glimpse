{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:34:45.464423Z",
     "iopub.status.busy": "2025-02-13T17:34:45.464104Z",
     "iopub.status.idle": "2025-02-13T17:34:52.784379Z",
     "shell.execute_reply": "2025-02-13T17:34:52.783145Z",
     "shell.execute_reply.started": "2025-02-13T17:34:45.464396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os.path\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PegasusTokenizer\n",
    "import datetime\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "sys.path.append('../rsasumm/')\n",
    "sys.path.append('../glimpse/evaluate/')\n",
    "from rsa_reranker import RSAReranking\n",
    "from evaluate_common_metrics_samples import evaluate_rouge\n",
    "from evaluate_bartbert_metrics import evaluate_bartbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run data processing if the folder ../data/processed doesn't contain processed files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:34:56.889509Z",
     "iopub.status.busy": "2025-02-13T17:34:56.889184Z",
     "iopub.status.idle": "2025-02-13T17:34:56.899956Z",
     "shell.execute_reply": "2025-02-13T17:34:56.899063Z",
     "shell.execute_reply.started": "2025-02-13T17:34:56.889482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path) -> Dataset: \n",
    "    try:\n",
    "        dataset = pd.read_csv(dataset_path)\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown dataset {dataset_path}\")\n",
    "\n",
    "    # make a dataset from the dataframe\n",
    "    dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def evaluate_summarizer(dataset: Dataset) -> Dataset:\n",
    "    \"\"\"\n",
    "    @param dataset: A dataset with the text\n",
    "    @return: The same dataset with the summaries added\n",
    "    \"\"\"\n",
    "\n",
    "    # generate summaries\n",
    "    summaries = []\n",
    "    print(\"Generating summaries...\")\n",
    "\n",
    "    # (tqdm library for progress bar) \n",
    "    for sample in tqdm(dataset):\n",
    "        text = sample[\"text\"] \n",
    "        \n",
    "        text = text.replace('-----', '\\n')\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        # remove empty sentences\n",
    "        sentences = [sentence for sentence in sentences if sentence != \"\"]\n",
    "        summaries.append(sentences)\n",
    "\n",
    "    # add summaries to the huggingface dataset\n",
    "    dataset = dataset.map(lambda example: {\"summary\": summaries.pop(0)})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def parse_summaries(summaries_dataset:Dataset) -> pd.DataFrame:\n",
    "    \n",
    "    try:\n",
    "        summaries = summaries_dataset\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown dataset! Error with summaries\")\n",
    "\n",
    "    # check if the dataframe has the right columns\n",
    "    if not all(\n",
    "        col in summaries.columns for col in [\"index\", \"id\", \"text\", \"gold\", \"summary\", \"id_candidate\"]\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The dataframe must have columns ['index', 'id', 'text', 'gold', 'summary', 'id_candidate']\"\n",
    "        )\n",
    "\n",
    "    return summaries\n",
    "\n",
    "def compute_rsa(summaries: pd.DataFrame, model, tokenizer, device):\n",
    "    results = []\n",
    "    for name, group in tqdm(summaries.groupby([\"id\"])):\n",
    "        rsa_reranker = RSAReranking(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            device=device,\n",
    "            candidates=group.summary.unique().tolist(),\n",
    "            source_texts=group.text.unique().tolist(),\n",
    "            batch_size=32,\n",
    "            rationality=3,\n",
    "        )\n",
    "        \n",
    "        (\n",
    "            best_rsa,\n",
    "            best_base,\n",
    "            speaker_df,\n",
    "            listener_df,\n",
    "            initial_listener,\n",
    "            language_model_proba_df,\n",
    "            initial_consensuality_scores,\n",
    "            consensuality_scores,\n",
    "        ) = rsa_reranker.rerank(t=2)\n",
    "\n",
    "        gold = group['gold'].tolist()[0]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": name,\n",
    "                \"best_rsa\": best_rsa,  # best speaker score\n",
    "                \"best_base\": best_base,  # naive baseline\n",
    "                \"speaker_df\": speaker_df,  # all speaker results\n",
    "                \"listener_df\": listener_df,  # all listener results (chances of guessing correctly)\n",
    "                \"initial_listener\": initial_listener,\n",
    "                \"language_model_proba_df\": language_model_proba_df,\n",
    "                \"initial_consensuality_scores\": initial_consensuality_scores,\n",
    "                \"consensuality_scores\": consensuality_scores,  # uniqueness scores\n",
    "                \"gold\": gold,\n",
    "                \"rationality\": 3,  # hyperparameter\n",
    "                \"text_candidates\" : group\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Extractive Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:35:04.888399Z",
     "iopub.status.busy": "2025-02-13T17:35:04.888066Z",
     "iopub.status.idle": "2025-02-13T17:35:04.961835Z",
     "shell.execute_reply": "2025-02-13T17:35:04.960970Z",
     "shell.execute_reply.started": "2025-02-13T17:35:04.888371Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2017 dataset\n",
      "Generating summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1511/1511 [00:00<00:00, 2763.22it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a41886e3d2415087cd1196d521995a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1511 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"../data/processed/all_reviews_2017.csv\"\n",
    "year = dataset_path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "print(f\"Using {year} dataset\")\n",
    "# |indexes| of reviews selected\n",
    "limit = None\n",
    "\n",
    "# prepare the dataset\n",
    "dataset = prepare_dataset(dataset_path)\n",
    "\n",
    "#limit the number of samples\n",
    "if limit is not None:\n",
    "    _lim = min(limit, len(dataset))\n",
    "    dataset = dataset.select(range(_lim))\n",
    "\n",
    "# generate summaries\n",
    "dataset = evaluate_summarizer(dataset)\n",
    "\n",
    "df_dataset = dataset.to_pandas()\n",
    "df_dataset = df_dataset.explode(\"summary\")\n",
    "df_dataset = df_dataset.reset_index()\n",
    "# add an idx with  the id of the summary for each example\n",
    "df_dataset[\"id_candidate\"] = df_dataset.groupby([\"index\"]).cumcount()\n",
    "\n",
    "# removing missing values\n",
    "if df_dataset.isnull().values.sum() > 0:\n",
    "    df_dataset.dropna(axis=0,inplace=True)\n",
    "    assert df_dataset.isnull().values.sum() == 0, \"Missing Values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:35:12.972379Z",
     "iopub.status.busy": "2025-02-13T17:35:12.972075Z",
     "iopub.status.idle": "2025-02-13T17:35:12.997960Z",
     "shell.execute_reply": "2025-02-13T17:35:12.997251Z",
     "shell.execute_reply.started": "2025-02-13T17:35:12.972353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "# create output dir if it doesn't exist\n",
    "output_dir = \"../data/candidates/\" \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df_dataset.to_csv(f\"{output_dir}extractive_summaries{year}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Abstractive summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T16:15:32.634679Z",
     "iopub.status.busy": "2025-02-11T16:15:32.634293Z",
     "iopub.status.idle": "2025-02-11T16:15:32.644975Z",
     "shell.execute_reply": "2025-02-11T16:15:32.644088Z",
     "shell.execute_reply.started": "2025-02-11T16:15:32.634636Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GENERATION_CONFIGS = {\n",
    "    \"top_p_sampling\": {\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.95,\n",
    "        \"temperature\": 1.0,\n",
    "        \"num_return_sequences\": 8,\n",
    "        \"num_beams\" : 1,\n",
    "\n",
    "        #\"num_beam_groups\" : 4,\n",
    "    },\n",
    "    **{\n",
    "        f\"sampling_topp_{str(topp).replace('.', '')}\": {\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"do_sample\": True,\n",
    "            \"num_return_sequences\": 8,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "        for topp in [0.5, 0.8, 0.95, 0.99]\n",
    "    },\n",
    "}\n",
    "\n",
    "# add base.csv config to all configs\n",
    "for key, value in GENERATION_CONFIGS.items():\n",
    "    GENERATION_CONFIGS[key] = {\n",
    "        # \"max_length\": 2048,\n",
    "        \"min_length\": 0,\n",
    "        \"early_stopping\": True,\n",
    "        **value,\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset_path) -> Dataset:\n",
    "    try:\n",
    "        dataset = pd.read_csv(dataset_path)\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown dataset {dataset_path}\")\n",
    "\n",
    "    # make a dataset from the dataframe\n",
    "    dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def evaluate_summarizer(\n",
    "    model, tokenizer, dataset: Dataset, decoding_config, batch_size: int,\n",
    "    device: str, trimming: bool\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    @param model: The model used to generate the summaries\n",
    "    @param tokenizer: The tokenizer used to tokenize the text and the summary\n",
    "    @param dataset: A dataset with the text\n",
    "    @param decoding_config: Dictionary with the decoding config\n",
    "    @param batch_size: The batch size used to generate the summaries\n",
    "    @return: The same dataset with the summaries added\n",
    "    \"\"\"\n",
    "    # create a dataset with the text and the summary\n",
    "\n",
    "    # create a dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=trimming)\n",
    "    # generate summaries\n",
    "    summaries = []\n",
    "    print(\"Generating summaries...\")\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        text = batch[\"text\"]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            max_length=1024,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # move inputs to device\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        # generate summaries\n",
    "        outputs = model.module.generate(\n",
    "            **inputs,\n",
    "            **decoding_config,\n",
    "        )\n",
    "\n",
    "        \n",
    "        total_size = outputs.numel()  # Total number of elements in the tensor\n",
    "        target_size = batch_size * outputs.shape[-1]  # Target size of the last dimension\n",
    "        pad_size = (target_size - (total_size % target_size)) % target_size  # Calculate the required padding size to make the total number of elements divisible by the target size\n",
    "\n",
    "        # Pad the tensor with zeros to make the total number of elements divisible by the target size\n",
    "        if not trimming and pad_size != 0: outputs = torch.nn.functional.pad(outputs, (0, 0, 0, pad_size // outputs.shape[-1]))\n",
    "\n",
    "        # output : (batch_size * num_return_sequences, max_length)\n",
    "        try:\n",
    "            outputs = outputs.reshape(batch_size, -1, outputs.shape[-1])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reshaping outputs: {e}\")\n",
    "            raise ValueError(f\"Cannot reshape tensor of size {outputs.numel()} into shape \"\n",
    "                            f\"({batch_size}, -1, {outputs.shape[-1]}).\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        # decode summaries\n",
    "        for b in range(batch_size):\n",
    "            summaries.append(\n",
    "                [\n",
    "                    tokenizer.decode(\n",
    "                        outputs[b, i],\n",
    "                        skip_special_tokens=True,\n",
    "                    )\n",
    "                    for i in range(outputs.shape[1])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    # if trimming the last batch, remove them from the dataset\n",
    "    if trimming: dataset = dataset.select(range(len(summaries)))\n",
    "    \n",
    "    # add summaries to the huggingface dataset\n",
    "    dataset = dataset.map(lambda example: {\"summary\": summaries.pop(0)})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def sanitize_model_name(model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize the model name to be used as a folder name.\n",
    "    @param model_name: The model name\n",
    "    @return: The sanitized model name\n",
    "    \"\"\"\n",
    "    return model_name.replace(\"/\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T16:19:23.137295Z",
     "iopub.status.busy": "2025-02-11T16:19:23.136968Z",
     "iopub.status.idle": "2025-02-11T16:22:27.161184Z",
     "shell.execute_reply": "2025-02-11T16:22:27.160552Z",
     "shell.execute_reply.started": "2025-02-11T16:19:23.137264Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "Using 2 GPUs!\n",
      "Loading dataset...\n",
      "Generating summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:695: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [03:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efdb75ccda746699f527d57e39ecbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using {device} device\")\n",
    "\n",
    "# Fixed configuration\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "dataset_path = \"../data/processed/all_reviews_2017.csv\"\n",
    "decoding_config = \"top_p_sampling\" \n",
    "batch_size = 32\n",
    "trimming = True\n",
    "output_dir = \"../data/candidates/\" \n",
    "limit = None  # You can change this value\n",
    "scripted_run = False\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "\n",
    "# Multiple GPU\n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model=nn.DataParallel(model)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = prepare_dataset(dataset_path)\n",
    "\n",
    "# Limit the number of samples\n",
    "_lim = min(limit, len(dataset))\n",
    "dataset = dataset.select(range(_lim))\n",
    "\n",
    "# Generate summaries\n",
    "dataset = evaluate_summarizer(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    GENERATION_CONFIGS[decoding_config],\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    trimming=trimming,\n",
    ")\n",
    "\n",
    "df_dataset = dataset.to_pandas()\n",
    "df_dataset = df_dataset.explode(\"summary\").reset_index()\n",
    "df_dataset['id_candidate'] = df_dataset.groupby(['index']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T16:23:06.858234Z",
     "iopub.status.busy": "2025-02-11T16:23:06.857917Z",
     "iopub.status.idle": "2025-02-11T16:23:06.905599Z",
     "shell.execute_reply": "2025-02-11T16:23:06.904842Z",
     "shell.execute_reply.started": "2025-02-11T16:23:06.858210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name_sanitized = sanitize_model_name(model_name)\n",
    "padding_status = \"trimmed\" if trimming else \"padded\"\n",
    "\n",
    "# save the dataset\n",
    "# create output dir if it doesn't exist\n",
    "output_dir = \"../data/candidates/\" \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df_dataset.to_csv(f\"{output_dir}abstractive_summaries{year}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:35:23.024595Z",
     "iopub.status.busy": "2025-02-13T17:35:23.024310Z",
     "iopub.status.idle": "2025-02-13T17:35:30.748293Z",
     "shell.execute_reply": "2025-02-13T17:35:30.746909Z",
     "shell.execute_reply.started": "2025-02-13T17:35:23.024574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-arxiv and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# download model\n",
    "model_name = \"google/pegasus-arxiv\"\n",
    "#summaries = \"/kaggle/working/candidates/extractive_summaries.csv\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using {device} device\")\n",
    "\n",
    "# load the model and the tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Multiple GPU \n",
    "model=model.to(device)\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model=nn.DataParallel(model)\n",
    "\n",
    "\n",
    "if \"pegasus\" in model_name: \n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:33:05.213798Z",
     "iopub.status.busy": "2025-02-13T17:33:05.213467Z",
     "iopub.status.idle": "2025-02-13T17:33:09.511186Z",
     "shell.execute_reply": "2025-02-13T17:33:09.509867Z",
     "shell.execute_reply.started": "2025-02-13T17:33:05.213765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_path = \"../output/quality/\"\n",
    "\n",
    "# load the summaries\n",
    "summaries = parse_summaries(df_dataset)\n",
    "n_articles = 'all_articles'\n",
    "# # take first 5 summary candidates for each id\n",
    "n_articles = 5\n",
    "selected_articles = list(summaries.groupby(\"id\").count().index[:n_articles])\n",
    "mask = [summaries[\"id\"][i] in selected_articles for i in range(len(summaries))]\n",
    "selected_summaries = summaries[mask]\n",
    "assert len(selected_summaries.groupby(\"id\").count()) == n_articles, \"Error in selecting articles!\"\n",
    "print(f\"using a dataset with {len(selected_summaries.groupby('id').count())} articles\")\n",
    "\n",
    "\n",
    "# rerank the summaries\n",
    "results = compute_rsa(selected_summaries, model, tokenizer, device)\n",
    "\n",
    "results = {\"results\": results}\n",
    "results[\"metadata/reranking_model\"] = model_name\n",
    "results[\"metadata/rsa_iterations\"] = 3\n",
    "\n",
    "print(\"Best Summaries generated succesfully!\")\n",
    "\n",
    "# save dataframe with base summaries\n",
    "all_base_df = pd.DataFrame(results[\"results\"])\n",
    "base_df = all_base_df.loc[:,[\"id\",\"best_rsa\",\"gold\"]]\n",
    "display(base_df)\n",
    "base_df.to_csv(f\"{output_path}base_glimpse_{year}_{n_articles}samples.csv\", index=False)\n",
    "\n",
    "# to get back some gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:27:49.643143Z",
     "iopub.status.busy": "2025-02-13T17:27:49.642722Z",
     "iopub.status.idle": "2025-02-13T17:28:12.127546Z",
     "shell.execute_reply": "2025-02-13T17:28:12.126406Z",
     "shell.execute_reply.started": "2025-02-13T17:27:49.643105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class QualityModel(nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, config):\n",
    "        super(QualityModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(config[\"base_model\"])\n",
    "        self.dropout = nn.Dropout(config[\"fc_dropout\"])\n",
    "        self.fc = nn.Linear(self.model.config.hidden_size, len(config[\"id2label\"]))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        features = self.model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state\n",
    "        dropped = self.dropout(features)\n",
    "        outputs = self.fc(dropped)\n",
    "        return torch.softmax(outputs[:, 0, :], dim=1)\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "config = AutoConfig.from_pretrained(\"nvidia/quality-classifier-deberta\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/quality-classifier-deberta\")\n",
    "model = QualityModel.from_pretrained(\"nvidia/quality-classifier-deberta\").to(device)\n",
    "model.eval()\n",
    "print(\"Model ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:28:16.926059Z",
     "iopub.status.busy": "2025-02-13T17:28:16.925706Z",
     "iopub.status.idle": "2025-02-13T17:28:46.145621Z",
     "shell.execute_reply": "2025-02-13T17:28:46.144816Z",
     "shell.execute_reply.started": "2025-02-13T17:28:16.926025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.84s/it]\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.DataFrame(results[\"results\"])\n",
    "# list of speaker matrixes\n",
    "mat_list = base_df.loc[:,\"speaker_df\"]\n",
    "# new dataframe that will collect improved summaries \n",
    "new_df = base_df.loc[:,[\"id\",\"best_rsa\",\"gold\"]]\n",
    "new_df.rename(columns={\"best_rsa\":\"base_rsa\"},inplace=True)\n",
    "new_df.insert(1, \"best_rsa\", \"0\", allow_duplicates=True)\n",
    "\n",
    "# use LLM to generate new summaries\n",
    "for i in tqdm(range(len(mat_list))):\n",
    "    # all potential summaries (sentences in reviews)\n",
    "    candidates_summ = list(mat_list[i].columns)\n",
    "    # tokenize and evaluate summaries\n",
    "    inputs = tokenizer(candidates_summ, return_tensors=\"pt\", padding=\"longest\", truncation=True).to(device)\n",
    "    outputs = model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "    \n",
    "    quality_scores_raw = outputs.cpu().detach().numpy()\n",
    "    # To get a quality score, we can sum the probability of \"High\" and 0.7 times the probability of \"Medium\". \n",
    "    # This is a simple heuristic to get a score between 0 and 1. \n",
    "    # \"Medium\" is multiplied by 0.7 to give it less importance than \"High\".\n",
    "    quality_scores = quality_scores_raw[:,0] + 0.7 * quality_scores_raw[:,1]\n",
    "\n",
    "    new_scores = mat_list[i] + quality_scores\n",
    "    new_df.loc[i,\"best_rsa\"] = str(new_scores.idxmax(axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Extractive RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:24:51.621820Z",
     "iopub.status.busy": "2025-02-13T17:24:51.621613Z",
     "iopub.status.idle": "2025-02-13T17:24:51.999784Z",
     "shell.execute_reply": "2025-02-13T17:24:51.998810Z",
     "shell.execute_reply.started": "2025-02-13T17:24:51.621801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Glimpse Scores\n",
      "     rouge1    rouge2    rougeL  rougeLsum\n",
      "0  0.073394  0.000000  0.055046   0.073394\n",
      "1  0.296296  0.025316  0.148148   0.148148\n",
      "2  0.224900  0.024291  0.120482   0.160643\n",
      "3  0.228070  0.035714  0.140351   0.175439\n",
      "4  0.133163  0.025674  0.071703   0.089629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rouge1       0.191165\n",
       "rouge2       0.022199\n",
       "rougeL       0.107146\n",
       "rougeLsum    0.129450\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input base_df.astype(\"str\") to get base scores, new_df to get improved ones\n",
    "metrics = evaluate_rouge(base_df.astype(\"str\"))\n",
    "df = pd.DataFrame.from_dict(metrics)\n",
    "# scores for the base model\n",
    "print(\"Base Glimpse Scores\")\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality-based Extractive RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:28:50.948178Z",
     "iopub.status.busy": "2025-02-13T17:28:50.947821Z",
     "iopub.status.idle": "2025-02-13T17:28:51.422008Z",
     "shell.execute_reply": "2025-02-13T17:28:51.421278Z",
     "shell.execute_reply.started": "2025-02-13T17:28:50.948140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Glimpse Scores\n",
      "     rouge1    rouge2    rougeL  rougeLsum\n",
      "0  0.213836  0.025478  0.163522   0.201258\n",
      "1  0.361111  0.042254  0.250000   0.291667\n",
      "2  0.284722  0.034965  0.152778   0.201389\n",
      "3  0.224852  0.047904  0.118343   0.177515\n",
      "4  0.175000  0.037594  0.095000   0.120000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rouge1       0.251904\n",
       "rouge2       0.037639\n",
       "rougeL       0.155929\n",
       "rougeLsum    0.198366\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input base_df.astype(\"str\") to get base scores, new_df to get improved ones\n",
    "metrics = evaluate_rouge(new_df.astype(\"str\"))\n",
    "df = pd.DataFrame.from_dict(metrics)\n",
    "# scores for the base model\n",
    "print(\"Base Glimpse Scores\")\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Abstractive RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T16:24:31.396264Z",
     "iopub.status.busy": "2025-02-11T16:24:31.395880Z",
     "iopub.status.idle": "2025-02-11T16:24:31.596126Z",
     "shell.execute_reply": "2025-02-11T16:24:31.595394Z",
     "shell.execute_reply.started": "2025-02-11T16:24:31.396227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Abstractive RSA Scores\n",
      "     rouge1    rouge2    rougeL  rougeLsum\n",
      "0  0.525253  0.418367  0.454545   0.515152\n",
      "1  0.307692  0.029126  0.192308   0.259615\n",
      "2  0.220994  0.033520  0.110497   0.165746\n",
      "3  0.107527  0.021739  0.086022   0.096774\n",
      "4  0.018692  0.000000  0.018692   0.018692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rouge1       0.236032\n",
       "rouge2       0.100550\n",
       "rougeL       0.172413\n",
       "rougeLsum    0.211196\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input base_df.astype(\"str\") to get base scores, new_df to get improved ones\n",
    "metrics = evaluate_rouge(base_df.astype(\"str\"))\n",
    "df = pd.DataFrame.from_dict(metrics)\n",
    "# scores for the base model\n",
    "print(\"Quality Abstractive RSA Scores\")\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality-based Abstractive RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T16:25:11.156152Z",
     "iopub.status.busy": "2025-02-11T16:25:11.155835Z",
     "iopub.status.idle": "2025-02-11T16:25:11.381445Z",
     "shell.execute_reply": "2025-02-11T16:25:11.380420Z",
     "shell.execute_reply.started": "2025-02-11T16:25:11.156125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Glimpse Scores\n",
      "     rouge1    rouge2    rougeL  rougeLsum\n",
      "0  0.587678  0.421053  0.483412   0.568720\n",
      "1  0.315353  0.041841  0.190871   0.265560\n",
      "2  0.220994  0.033520  0.110497   0.165746\n",
      "3  0.101852  0.028037  0.074074   0.074074\n",
      "4  0.013889  0.000000  0.013889   0.013889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rouge1       0.247953\n",
       "rouge2       0.104890\n",
       "rougeL       0.174549\n",
       "rougeLsum    0.217598\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input base_df.astype(\"str\") to get base scores, new_df to get improved ones\n",
    "metrics = evaluate_rouge(new_df)\n",
    "df = pd.DataFrame.from_dict(metrics)\n",
    "# scores for the base model\n",
    "print(\"Base Glimpse Scores\")\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bartbert Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Extractive RSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:26:34.238025Z",
     "iopub.status.busy": "2025-02-13T17:26:34.237701Z",
     "iopub.status.idle": "2025-02-13T17:26:43.392128Z",
     "shell.execute_reply": "2025-02-13T17:26:43.391365Z",
     "shell.execute_reply.started": "2025-02-13T17:26:34.237997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1-Hhnslg,)</td>\n",
       "      <td>[1)., Instead of considering each support poin...</td>\n",
       "      <td>The program committee appreciates the authors'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=B1-q5Pqxl,)</td>\n",
       "      <td>[The paper looks at the problem of locating th...</td>\n",
       "      <td>This paper provides two approaches to question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=B16Jem9xe,)</td>\n",
       "      <td>[I just noticed I submitted my review as a pre...</td>\n",
       "      <td>Hello Authors,  Congratulations on the accepta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=B16dGcqlx,)</td>\n",
       "      <td>[This paper proposed a novel adversarial frame...</td>\n",
       "      <td>pros:  - new problem  - huge number of experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=B184E5qee,)</td>\n",
       "      <td>[Unlike much related work in neural networks w...</td>\n",
       "      <td>Reviewers agree that this paper is based on a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1-Hhnslg,)   \n",
       "1  (https://openreview.net/forum?id=B1-q5Pqxl,)   \n",
       "2  (https://openreview.net/forum?id=B16Jem9xe,)   \n",
       "3  (https://openreview.net/forum?id=B16dGcqlx,)   \n",
       "4  (https://openreview.net/forum?id=B184E5qee,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  [1)., Instead of considering each support poin...   \n",
       "1  [The paper looks at the problem of locating th...   \n",
       "2  [I just noticed I submitted my review as a pre...   \n",
       "3  [This paper proposed a novel adversarial frame...   \n",
       "4  [Unlike much related work in neural networks w...   \n",
       "\n",
       "                                                gold  \n",
       "0  The program committee appreciates the authors'...  \n",
       "1  This paper provides two approaches to question...  \n",
       "2  Hello Authors,  Congratulations on the accepta...  \n",
       "3  pros:  - new problem  - huge number of experim...  \n",
       "4  Reviewers agree that this paper is based on a ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff22c03eaa5b49a2ad24847dff2f084e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a651ba9f83ff4acea7ed06ea6b438de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5340f74e48fa4de6b41e3a60d08a86fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02daf045015a449e9c96df6605bf5353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df264c4cc8194c0eb8dfa7b43c35be13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7cbd9da4c74ee1a83bfd0454886440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BERTScore\n",
      "0   0.810492\n",
      "1   0.819667\n",
      "2   0.802348\n",
      "3   0.814407\n",
      "4   0.812400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTScore    0.811863\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(base_df)\n",
    "metrics = evaluate_bartbert(base_df.astype(\"str\"))\n",
    "# make a dataframe with the metric\n",
    "df = pd.DataFrame(metrics)\n",
    "# merge the metrics with the summaries\n",
    "#bert_df = pd.concat([rouge_df,df], axis=1)\n",
    "#bert_df\n",
    "# base model bartbert scores\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Extractive RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:30:04.352986Z",
     "iopub.status.busy": "2025-02-13T17:30:04.352600Z",
     "iopub.status.idle": "2025-02-13T17:30:05.617852Z",
     "shell.execute_reply": "2025-02-13T17:30:05.616840Z",
     "shell.execute_reply.started": "2025-02-13T17:30:04.352951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>base_rsa</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1-Hhnslg,)</td>\n",
       "      <td>['It seems to me when dealing with 1-shot case...</td>\n",
       "      <td>[1)., Instead of considering each support poin...</td>\n",
       "      <td>The program committee appreciates the authors'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=B1-q5Pqxl,)</td>\n",
       "      <td>['For this the paper proposes to combine two e...</td>\n",
       "      <td>[The paper looks at the problem of locating th...</td>\n",
       "      <td>This paper provides two approaches to question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=B16Jem9xe,)</td>\n",
       "      <td>['A variant of least-squares likelihood estima...</td>\n",
       "      <td>[I just noticed I submitted my review as a pre...</td>\n",
       "      <td>Hello Authors,  Congratulations on the accepta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=B16dGcqlx,)</td>\n",
       "      <td>['This paper proposed a novel adversarial fram...</td>\n",
       "      <td>[This paper proposed a novel adversarial frame...</td>\n",
       "      <td>pros:  - new problem  - huge number of experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=B184E5qee,)</td>\n",
       "      <td>['The authors present a simple method to affix...</td>\n",
       "      <td>[Unlike much related work in neural networks w...</td>\n",
       "      <td>Reviewers agree that this paper is based on a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1-Hhnslg,)   \n",
       "1  (https://openreview.net/forum?id=B1-q5Pqxl,)   \n",
       "2  (https://openreview.net/forum?id=B16Jem9xe,)   \n",
       "3  (https://openreview.net/forum?id=B16dGcqlx,)   \n",
       "4  (https://openreview.net/forum?id=B184E5qee,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  ['It seems to me when dealing with 1-shot case...   \n",
       "1  ['For this the paper proposes to combine two e...   \n",
       "2  ['A variant of least-squares likelihood estima...   \n",
       "3  ['This paper proposed a novel adversarial fram...   \n",
       "4  ['The authors present a simple method to affix...   \n",
       "\n",
       "                                            base_rsa  \\\n",
       "0  [1)., Instead of considering each support poin...   \n",
       "1  [The paper looks at the problem of locating th...   \n",
       "2  [I just noticed I submitted my review as a pre...   \n",
       "3  [This paper proposed a novel adversarial frame...   \n",
       "4  [Unlike much related work in neural networks w...   \n",
       "\n",
       "                                                gold  \n",
       "0  The program committee appreciates the authors'...  \n",
       "1  This paper provides two approaches to question...  \n",
       "2  Hello Authors,  Congratulations on the accepta...  \n",
       "3  pros:  - new problem  - huge number of experim...  \n",
       "4  Reviewers agree that this paper is based on a ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BERTScore\n",
      "0   0.817730\n",
      "1   0.840635\n",
      "2   0.809344\n",
      "3   0.812275\n",
      "4   0.818157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTScore    0.819628\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(new_df)\n",
    "metrics = evaluate_bartbert(new_df.astype(\"str\"))\n",
    "# make a dataframe with the metric\n",
    "df = pd.DataFrame(metrics)\n",
    "# merge the metrics with the summaries\n",
    "#bert_df = pd.concat([rouge_df,df], axis=1)\n",
    "#bert_df\n",
    "# base model bartbert scores\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Abstractive RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T16:31:50.680094Z",
     "iopub.status.busy": "2025-02-11T16:31:50.679765Z",
     "iopub.status.idle": "2025-02-11T16:31:52.149327Z",
     "shell.execute_reply": "2025-02-11T16:31:52.148415Z",
     "shell.execute_reply.started": "2025-02-11T16:31:50.680065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>best_base</th>\n",
       "      <th>speaker_df</th>\n",
       "      <th>listener_df</th>\n",
       "      <th>initial_listener</th>\n",
       "      <th>language_model_proba_df</th>\n",
       "      <th>initial_consensuality_scores</th>\n",
       "      <th>consensuality_scores</th>\n",
       "      <th>gold</th>\n",
       "      <th>rationality</th>\n",
       "      <th>text_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1jnyXXJx,)</td>\n",
       "      <td>[Paleo-Ferrari-Barrini (2015) a regularizer th...</td>\n",
       "      <td>[Paleo-Ferrari-Barrini (2015) a regularizer th...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>This article looks at an optimization method u...</td>\n",
       "      <td>This article looks at an optimization method u...</td>\n",
       "      <td>The paper proposes a method for accelerating o...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=BJ46w6Ule,)</td>\n",
       "      <td>[The paper addresses the problem of learning c...</td>\n",
       "      <td>[The paper addresses the problem of learning c...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>The paper addresses the problem of learning co...</td>\n",
       "      <td>The paper addresses the problem of learning co...</td>\n",
       "      <td>This paper is about learning distributed repre...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=BJO-BuT1g,)</td>\n",
       "      <td>[This paper addresses the problem of efficient...</td>\n",
       "      <td>[This paper addresses the problem of efficient...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper addresses the problem of efficient ...</td>\n",
       "      <td>This paper addresses the problem of efficient ...</td>\n",
       "      <td>The reviewers (two of whom stated maximum conf...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=Bk8N0RLxx,)</td>\n",
       "      <td>[This paper conducts a series of experiments o...</td>\n",
       "      <td>[This paper conducts a series of experiments o...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>This paper conducts a series of experiments on...</td>\n",
       "      <td>This paper conducts a series of experiments on...</td>\n",
       "      <td>The reviewers agree that the method is excitin...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=BkCPyXm1l,)</td>\n",
       "      <td>[The paper introduced a regularization scheme ...</td>\n",
       "      <td>[The paper introduced a regularization scheme ...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>Cons: Bad baseline results. Poor consistency w...</td>\n",
       "      <td>Cons: Bad baseline results. Poor consistency w...</td>\n",
       "      <td>The reviewers unanimously recommend rejection.</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1jnyXXJx,)   \n",
       "1  (https://openreview.net/forum?id=BJ46w6Ule,)   \n",
       "2  (https://openreview.net/forum?id=BJO-BuT1g,)   \n",
       "3  (https://openreview.net/forum?id=Bk8N0RLxx,)   \n",
       "4  (https://openreview.net/forum?id=BkCPyXm1l,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  [Paleo-Ferrari-Barrini (2015) a regularizer th...   \n",
       "1  [The paper addresses the problem of learning c...   \n",
       "2  [This paper addresses the problem of efficient...   \n",
       "3  [This paper conducts a series of experiments o...   \n",
       "4  [The paper introduced a regularization scheme ...   \n",
       "\n",
       "                                           best_base  \\\n",
       "0  [Paleo-Ferrari-Barrini (2015) a regularizer th...   \n",
       "1  [The paper addresses the problem of learning c...   \n",
       "2  [This paper addresses the problem of efficient...   \n",
       "3  [This paper conducts a series of experiments o...   \n",
       "4  [The paper introduced a regularization scheme ...   \n",
       "\n",
       "                                          speaker_df  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                                         listener_df  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                                    initial_listener  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                             language_model_proba_df  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                        initial_consensuality_scores  \\\n",
       "0  This article looks at an optimization method u...   \n",
       "1  The paper addresses the problem of learning co...   \n",
       "2  This paper addresses the problem of efficient ...   \n",
       "3  This paper conducts a series of experiments on...   \n",
       "4  Cons: Bad baseline results. Poor consistency w...   \n",
       "\n",
       "                                consensuality_scores  \\\n",
       "0  This article looks at an optimization method u...   \n",
       "1  The paper addresses the problem of learning co...   \n",
       "2  This paper addresses the problem of efficient ...   \n",
       "3  This paper conducts a series of experiments on...   \n",
       "4  Cons: Bad baseline results. Poor consistency w...   \n",
       "\n",
       "                                                gold  rationality  \\\n",
       "0  The paper proposes a method for accelerating o...            3   \n",
       "1  This paper is about learning distributed repre...            3   \n",
       "2  The reviewers (two of whom stated maximum conf...            3   \n",
       "3  The reviewers agree that the method is excitin...            3   \n",
       "4     The reviewers unanimously recommend rejection.            3   \n",
       "\n",
       "                                     text_candidates  \n",
       "0      index                                     ...  \n",
       "1       index                                    ...  \n",
       "2       index                                    ...  \n",
       "3       index                                    ...  \n",
       "4      index                                     ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BERTScore\n",
      "0   0.886830\n",
      "1   0.831309\n",
      "2   0.822337\n",
      "3   0.830322\n",
      "4   0.825558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTScore    0.839271\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(base_df)\n",
    "metrics = evaluate_bartbert(base_df.astype(\"str\"))\n",
    "# make a dataframe with the metric\n",
    "df = pd.DataFrame(metrics)\n",
    "# merge the metrics with the summaries\n",
    "#bert_df = pd.concat([rouge_df,df], axis=1)\n",
    "#bert_df\n",
    "# base model bartbert scores\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Abstractive RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>base_rsa</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1jnyXXJx,)</td>\n",
       "      <td>['The method is inspired from physics and uses...</td>\n",
       "      <td>[Paleo-Ferrari-Barrini (2015) a regularizer th...</td>\n",
       "      <td>The paper proposes a method for accelerating o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=BJ46w6Ule,)</td>\n",
       "      <td>['The paper addresses the problem of learning ...</td>\n",
       "      <td>[The paper addresses the problem of learning c...</td>\n",
       "      <td>This paper is about learning distributed repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=BJO-BuT1g,)</td>\n",
       "      <td>['This paper addresses the problem of efficien...</td>\n",
       "      <td>[This paper addresses the problem of efficient...</td>\n",
       "      <td>The reviewers (two of whom stated maximum conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=Bk8N0RLxx,)</td>\n",
       "      <td>['This paper conducts a series of experiments ...</td>\n",
       "      <td>[This paper conducts a series of experiments o...</td>\n",
       "      <td>The reviewers agree that the method is excitin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=BkCPyXm1l,)</td>\n",
       "      <td>['The paper introduced a regularization scheme...</td>\n",
       "      <td>[The paper introduced a regularization scheme ...</td>\n",
       "      <td>The reviewers unanimously recommend rejection.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1jnyXXJx,)   \n",
       "1  (https://openreview.net/forum?id=BJ46w6Ule,)   \n",
       "2  (https://openreview.net/forum?id=BJO-BuT1g,)   \n",
       "3  (https://openreview.net/forum?id=Bk8N0RLxx,)   \n",
       "4  (https://openreview.net/forum?id=BkCPyXm1l,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  ['The method is inspired from physics and uses...   \n",
       "1  ['The paper addresses the problem of learning ...   \n",
       "2  ['This paper addresses the problem of efficien...   \n",
       "3  ['This paper conducts a series of experiments ...   \n",
       "4  ['The paper introduced a regularization scheme...   \n",
       "\n",
       "                                            base_rsa  \\\n",
       "0  [Paleo-Ferrari-Barrini (2015) a regularizer th...   \n",
       "1  [The paper addresses the problem of learning c...   \n",
       "2  [This paper addresses the problem of efficient...   \n",
       "3  [This paper conducts a series of experiments o...   \n",
       "4  [The paper introduced a regularization scheme ...   \n",
       "\n",
       "                                                gold  \n",
       "0  The paper proposes a method for accelerating o...  \n",
       "1  This paper is about learning distributed repre...  \n",
       "2  The reviewers (two of whom stated maximum conf...  \n",
       "3  The reviewers agree that the method is excitin...  \n",
       "4     The reviewers unanimously recommend rejection.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BERTScore\n",
      "0   0.895531\n",
      "1   0.840526\n",
      "2   0.822337\n",
      "3   0.828523\n",
      "4   0.821937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTScore    0.841771\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(new_df)\n",
    "metrics = evaluate_bartbert(new_df.astype(\"str\"))\n",
    "# make a dataframe with the metric\n",
    "df = pd.DataFrame(metrics)\n",
    "# merge the metrics with the summaries\n",
    "#bert_df = pd.concat([rouge_df,df], axis=1)\n",
    "#bert_df\n",
    "# base model bartbert scores\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6558301,
     "sourceId": 10597484,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6614693,
     "sourceId": 10678162,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6655621,
     "sourceId": 10734523,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
