{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:32:57.237784Z",
     "iopub.status.busy": "2025-02-14T11:32:57.237505Z",
     "iopub.status.idle": "2025-02-14T11:33:18.996771Z",
     "shell.execute_reply": "2025-02-14T11:33:18.995777Z",
     "shell.execute_reply.started": "2025-02-14T11:32:57.237760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os.path\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PegasusTokenizer\n",
    "import datetime\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "from functools import cache\n",
    "from typing import List\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline \n",
    "\n",
    "sys.path.append('../glimpse/evaluate/')\n",
    "from evaluate_common_metrics_samples import evaluate_rouge\n",
    "from evaluate_bartbert_metrics import evaluate_bartbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run data processing if the folder ../data/processed doesn't contain processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:36:50.393605Z",
     "iopub.status.busy": "2025-02-14T11:36:50.393212Z",
     "iopub.status.idle": "2025-02-14T11:36:50.404027Z",
     "shell.execute_reply": "2025-02-14T11:36:50.403051Z",
     "shell.execute_reply.started": "2025-02-14T11:36:50.393573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path) -> Dataset: \n",
    "    try:\n",
    "        dataset = pd.read_csv(dataset_path)\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown dataset {dataset_path}\")\n",
    "\n",
    "    # make a dataset from the dataframe\n",
    "    dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def evaluate_summarizer(dataset: Dataset) -> Dataset:\n",
    "    \"\"\"\n",
    "    @param dataset: A dataset with the text\n",
    "    @return: The same dataset with the summaries added\n",
    "    \"\"\"\n",
    "\n",
    "    # generate summaries\n",
    "    summaries = []\n",
    "    print(\"Generating summaries...\")\n",
    "\n",
    "    # (tqdm library for progress bar) \n",
    "    for sample in tqdm(dataset):\n",
    "        text = sample[\"text\"] \n",
    "        \n",
    "        text = text.replace('-----', '\\n')\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        # remove empty sentences\n",
    "        sentences = [sentence for sentence in sentences if sentence != \"\"]\n",
    "        summaries.append(sentences)\n",
    "\n",
    "    # add summaries to the huggingface dataset\n",
    "    dataset = dataset.map(lambda example: {\"summary\": summaries.pop(0)})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def parse_summaries(summaries_dataset:Dataset) -> pd.DataFrame:\n",
    "    \n",
    "    try:\n",
    "        summaries = summaries_dataset\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown dataset! Error with summaries\")\n",
    "\n",
    "    # check if the dataframe has the right columns\n",
    "    if not all(\n",
    "        col in summaries.columns for col in [\"index\", \"id\", \"text\", \"gold\", \"summary\", \"id_candidate\"]\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The dataframe must have columns ['index', 'id', 'text', 'gold', 'summary', 'id_candidate']\"\n",
    "        )\n",
    "\n",
    "    return summaries\n",
    "\n",
    "def compute_rsa(summaries: pd.DataFrame, model, tokenizer, device):\n",
    "    results = []\n",
    "    for name, group in tqdm(summaries.groupby([\"id\"])):\n",
    "        rsa_reranker = RSAReranking(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            device=device,\n",
    "            candidates=group.summary.unique().tolist(),\n",
    "            source_texts=group.text.unique().tolist(),\n",
    "            batch_size=32,\n",
    "            rationality=3,\n",
    "        )\n",
    "        \n",
    "        (\n",
    "            best_rsa,\n",
    "            best_base,\n",
    "            speaker_df,\n",
    "            listener_df,\n",
    "            initial_listener,\n",
    "            language_model_proba_df,\n",
    "            initial_consensuality_scores,\n",
    "            consensuality_scores,\n",
    "        ) = rsa_reranker.rerank(t=2)\n",
    "\n",
    "        gold = group['gold'].tolist()[0]\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": name,\n",
    "                \"best_rsa\": best_rsa,  # best speaker score\n",
    "                \"best_base\": best_base,  # naive baseline\n",
    "                \"speaker_df\": speaker_df,  # all speaker results\n",
    "                \"listener_df\": listener_df,  # all listener results (chances of guessing correctly)\n",
    "                \"initial_listener\": initial_listener,\n",
    "                \"language_model_proba_df\": language_model_proba_df,\n",
    "                \"initial_consensuality_scores\": initial_consensuality_scores,\n",
    "                \"consensuality_scores\": consensuality_scores,  # uniqueness scores\n",
    "                \"gold\": gold,\n",
    "                \"rationality\": 3,  # hyperparameter\n",
    "                \"text_candidates\" : group\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Extractive Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:10:03.445032Z",
     "iopub.status.busy": "2025-02-14T11:10:03.444698Z",
     "iopub.status.idle": "2025-02-14T11:10:03.564691Z",
     "shell.execute_reply": "2025-02-14T11:10:03.564028Z",
     "shell.execute_reply.started": "2025-02-14T11:10:03.444989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ita dataset\n",
      "Generating summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 557.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05292ec316d746009606722833ffb64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"../data/processed/all_reviews_2017.csv\"\n",
    "year = dataset_path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "print(f\"Using {year} dataset\")\n",
    "# |indexes| of reviews selected\n",
    "limit = None\n",
    "\n",
    "# prepare the dataset\n",
    "dataset = prepare_dataset(dataset_path)\n",
    "\n",
    "#limit the number of samples\n",
    "if limit is not None:\n",
    "    _lim = min(limit, len(dataset))\n",
    "    dataset = dataset.select(range(_lim))\n",
    "\n",
    "# generate summaries\n",
    "dataset = evaluate_summarizer(dataset)\n",
    "\n",
    "df_dataset = dataset.to_pandas()\n",
    "df_dataset = df_dataset.explode(\"summary\")\n",
    "df_dataset = df_dataset.reset_index()\n",
    "# add an idx with  the id of the summary for each example\n",
    "df_dataset[\"id_candidate\"] = df_dataset.groupby([\"index\"]).cumcount()\n",
    "\n",
    "# removing missing values\n",
    "if df_dataset.isnull().values.sum() > 0:\n",
    "    df_dataset.dropna(axis=0,inplace=True)\n",
    "    assert df_dataset.isnull().values.sum() == 0, \"Missing Values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T17:48:39.438419Z",
     "iopub.status.busy": "2025-02-13T17:48:39.438124Z",
     "iopub.status.idle": "2025-02-13T17:48:39.460763Z",
     "shell.execute_reply": "2025-02-13T17:48:39.460153Z",
     "shell.execute_reply.started": "2025-02-13T17:48:39.438376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "# create output dir if it doesn't exist\n",
    "output_dir = \"../data/candidates/\" \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df_dataset.to_csv(f\"{output_dir}extractive_summaries{year}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Abstractive summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:33:31.700156Z",
     "iopub.status.busy": "2025-02-14T11:33:31.699816Z",
     "iopub.status.idle": "2025-02-14T11:33:31.712132Z",
     "shell.execute_reply": "2025-02-14T11:33:31.711115Z",
     "shell.execute_reply.started": "2025-02-14T11:33:31.700126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GENERATION_CONFIGS = {\n",
    "    \"top_p_sampling\": {\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.95,\n",
    "        \"temperature\": 1.0,\n",
    "        \"num_return_sequences\": 8,\n",
    "        \"num_beams\" : 1,\n",
    "\n",
    "        #\"num_beam_groups\" : 4,\n",
    "    },\n",
    "    **{\n",
    "        f\"sampling_topp_{str(topp).replace('.', '')}\": {\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"do_sample\": True,\n",
    "            \"num_return_sequences\": 8,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "        for topp in [0.5, 0.8, 0.95, 0.99]\n",
    "    },\n",
    "}\n",
    "\n",
    "# add base.csv config to all configs\n",
    "for key, value in GENERATION_CONFIGS.items():\n",
    "    GENERATION_CONFIGS[key] = {\n",
    "        # \"max_length\": 2048,\n",
    "        \"min_length\": 0,\n",
    "        \"early_stopping\": True,\n",
    "        **value,\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset_path) -> Dataset:\n",
    "    try:\n",
    "        dataset = pd.read_csv(dataset_path)\n",
    "    except:\n",
    "        raise ValueError(f\"Unknown dataset {dataset_path}\")\n",
    "\n",
    "    # make a dataset from the dataframe\n",
    "    dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def evaluate_summarizer(\n",
    "    model, tokenizer, dataset: Dataset, decoding_config, batch_size: int,\n",
    "    device: str, trimming: bool\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    @param model: The model used to generate the summaries\n",
    "    @param tokenizer: The tokenizer used to tokenize the text and the summary\n",
    "    @param dataset: A dataset with the text\n",
    "    @param decoding_config: Dictionary with the decoding config\n",
    "    @param batch_size: The batch size used to generate the summaries\n",
    "    @return: The same dataset with the summaries added\n",
    "    \"\"\"\n",
    "    # create a dataset with the text and the summary\n",
    "\n",
    "    # create a dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=trimming)\n",
    "    # generate summaries\n",
    "    summaries = []\n",
    "    print(\"Generating summaries...\")\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        text = batch[\"text\"]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            max_length=1024,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # move inputs to device\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        # generate summaries\n",
    "        outputs = model.module.generate(\n",
    "            **inputs,\n",
    "            **decoding_config,\n",
    "        )\n",
    "\n",
    "        \n",
    "        total_size = outputs.numel()  # Total number of elements in the tensor\n",
    "        target_size = batch_size * outputs.shape[-1]  # Target size of the last dimension\n",
    "        pad_size = (target_size - (total_size % target_size)) % target_size  # Calculate the required padding size to make the total number of elements divisible by the target size\n",
    "\n",
    "        # Pad the tensor with zeros to make the total number of elements divisible by the target size\n",
    "        if not trimming and pad_size != 0: outputs = torch.nn.functional.pad(outputs, (0, 0, 0, pad_size // outputs.shape[-1]))\n",
    "\n",
    "        # output : (batch_size * num_return_sequences, max_length)\n",
    "        try:\n",
    "            outputs = outputs.reshape(batch_size, -1, outputs.shape[-1])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reshaping outputs: {e}\")\n",
    "            raise ValueError(f\"Cannot reshape tensor of size {outputs.numel()} into shape \"\n",
    "                            f\"({batch_size}, -1, {outputs.shape[-1]}).\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        # decode summaries\n",
    "        for b in range(batch_size):\n",
    "            summaries.append(\n",
    "                [\n",
    "                    tokenizer.decode(\n",
    "                        outputs[b, i],\n",
    "                        skip_special_tokens=True,\n",
    "                    )\n",
    "                    for i in range(outputs.shape[1])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    # if trimming the last batch, remove them from the dataset\n",
    "    if trimming: dataset = dataset.select(range(len(summaries)))\n",
    "    \n",
    "    # add summaries to the huggingface dataset\n",
    "    dataset = dataset.map(lambda example: {\"summary\": summaries.pop(0)})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def sanitize_model_name(model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize the model name to be used as a folder name.\n",
    "    @param model_name: The model name\n",
    "    @return: The sanitized model name\n",
    "    \"\"\"\n",
    "    return model_name.replace(\"/\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:33:40.418771Z",
     "iopub.status.busy": "2025-02-14T11:33:40.418402Z",
     "iopub.status.idle": "2025-02-14T11:34:38.673314Z",
     "shell.execute_reply": "2025-02-14T11:34:38.672164Z",
     "shell.execute_reply.started": "2025-02-14T11:33:40.418747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903254338c4a4a0d8b253c4457190d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17b261f04c141fdb007228ec0932965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0d146305fa40b68b1c5ea7e46d8137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bf603210e54d11b0e66e51022582ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1032a842fe34576bb75b46b1bcd0c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5124b846f3d54369a588f291c63798ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n",
      "Loading dataset...\n",
      "Generating summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:695: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [00:34<00:00,  1.71s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8928b2ca3a46f0be3306a1955d53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using {device} device\")\n",
    "\n",
    "# Fixed configuration\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "dataset_path = \"/kaggle/working/processed/all_reviews_2017.csv\"\n",
    "decoding_config = \"top_p_sampling\"  # Assuming GENERATION_CONFIGS exists\n",
    "batch_size = 32\n",
    "trimming = True\n",
    "output_dir = \"/kaggle/working/candidates/\"\n",
    "limit = None # You can change this value\n",
    "scripted_run = False\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "\n",
    "# Multiple GPU\n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model=nn.DataParallel(model)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = prepare_dataset(dataset_path)\n",
    "\n",
    "# Limit the number of samples\n",
    "_lim = min(limit, len(dataset))\n",
    "dataset = dataset.select(range(_lim))\n",
    "\n",
    "# Generate summaries\n",
    "dataset = evaluate_summarizer(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    GENERATION_CONFIGS[decoding_config],\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    trimming=trimming,\n",
    ")\n",
    "\n",
    "\n",
    "df_dataset = dataset.to_pandas()\n",
    "df_dataset = df_dataset.explode(\"summary\").reset_index()\n",
    "df_dataset['id_candidate'] = df_dataset.groupby(['index']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:34:42.344457Z",
     "iopub.status.busy": "2025-02-14T11:34:42.344072Z",
     "iopub.status.idle": "2025-02-14T11:34:42.361971Z",
     "shell.execute_reply": "2025-02-14T11:34:42.360919Z",
     "shell.execute_reply.started": "2025-02-14T11:34:42.344427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name_sanitized = sanitize_model_name(model_name)\n",
    "padding_status = \"trimmed\" if trimming else \"padded\"\n",
    "\n",
    "# save the dataset\n",
    "# create output dir if it doesn't exist\n",
    "output_dir = \"../data/candidates/\" \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df_dataset.to_csv(f\"{output_dir}abstractive_summaries{year}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute RSA with Sentiment Analysis\n",
    "Label each summary with sentiment, matching between sentiments may make identification of documente during rsa more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:37:09.960259Z",
     "iopub.status.busy": "2025-02-14T11:37:09.959937Z",
     "iopub.status.idle": "2025-02-14T11:37:09.988156Z",
     "shell.execute_reply": "2025-02-14T11:37:09.986927Z",
     "shell.execute_reply.started": "2025-02-14T11:37:09.960233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def filter_best_rsa_by_sentiment(best_rsa, meta_review, rsareranker):\n",
    "    \"\"\"\n",
    "    MODIFICA: Filter the list of candidate summaries (best_rsa) keeping only those whose sentiment corresponds \n",
    "    to that of the metareview\n",
    "    \"\"\"\n",
    "    meta_sentiment = rsareranker.get_sentiment(meta_review)\n",
    "    filtered_candidates = []\n",
    "    for candidate in best_rsa:\n",
    "        candidate_sentiment = rsareranker.get_sentiment(candidate)\n",
    "        if candidate_sentiment == meta_sentiment:\n",
    "            filtered_candidates.append(candidate)\n",
    "\n",
    "    return filtered_candidates if len(filtered_candidates) > 0 else best_rsa\n",
    "\n",
    "\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between two distributions\n",
    "    \"\"\"\n",
    "    return torch.nan_to_num(p * (p / q).log(), nan=0.0).sum(-1)\n",
    "\n",
    "\n",
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Compute the Jensen-Shannon divergence between two distributions\n",
    "    \"\"\"\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (kl_divergence(p, m) + kl_divergence(q, m))\n",
    "\n",
    "\n",
    "class RSAReranking:\n",
    "    \"\"\"\n",
    "    Rerank a list of candidates according to the RSA model.\n",
    "    MODIFICA: Integrazione del sentiment analysis per aggiungere bonus al punteggio.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            candidates: List[str],\n",
    "            source_texts: List[str],\n",
    "            batch_size: int = 32,\n",
    "            rationality: int = 1,\n",
    "            device=\"cpu\",\n",
    "            sentiment_weight: float = 1.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param model: hf model used to compute the likelihoods (supposed to be a seq2seq model), is S0 in the RSA model\n",
    "        :param tokenizer:\n",
    "        :param candidates: list of candidate summaries\n",
    "        :param source_texts: list of source texts (ad es. metareview gold)\n",
    "        :param batch_size: batch size used to compute the likelihoods (can be high since we don't need gradients and it's a single forward pass)\n",
    "        :param rationality: rationality parameter of the RSA model\n",
    "        :param device: device used to compute the likelihoods\n",
    "        :param sentiment_weight: fattore per integrare il bonus del sentiment\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.candidates = candidates\n",
    "        self.source_texts = source_texts\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.rationality = rationality\n",
    "        self.sentiment_weight = sentiment_weight \n",
    "\n",
    "        # Sentiment analysis pipeline\n",
    "        self.sentiment_analyzer = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            device=0 if device != \"cpu\" else -1\n",
    "        )\n",
    "\n",
    "    def compute_conditionned_likelihood(\n",
    "            self, x: List[str], y: List[str], mean: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the likelihood of y given x\n",
    "\n",
    "        :param x: list of source texts len(x) = batch_size\n",
    "        :param y: list of candidate summaries len(y) = batch_size\n",
    "        :param mean: average the likelihoods over the tokens of y or take the sum\n",
    "        :return: tensor of shape (batch_size) containing the likelihoods of y given x\n",
    "        \"\"\"\n",
    "\n",
    "        assert len(x) == len(y), \"x and y must have the same length\"\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        batch_size = len(x)\n",
    "\n",
    "        x_enc = self.tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        y_enc = self.tokenizer(y, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        x_ids = x_enc.input_ids.to(self.device)\n",
    "        y_ids = y_enc.input_ids.to(self.device)\n",
    "\n",
    "        logits = self.model(\n",
    "            input_ids=x_ids,\n",
    "            decoder_input_ids=y_ids,\n",
    "            attention_mask=x_enc.attention_mask.to(self.device),\n",
    "            decoder_attention_mask=y_enc.attention_mask.to(self.device),\n",
    "        ).logits\n",
    "\n",
    "        shifted_logits = logits[..., :-1, :].contiguous()\n",
    "        shifted_ids = y_ids[..., 1:].contiguous()\n",
    "\n",
    "        likelihood = -loss_fn(\n",
    "            shifted_logits.view(-1, shifted_logits.size(-1)), shifted_ids.view(-1)\n",
    "        )\n",
    "\n",
    "        likelihood = likelihood.view(batch_size, -1).sum(-1)\n",
    "        if mean:\n",
    "            likelihood /= (y_ids != self.tokenizer.pad_token_id).float().sum(-1)\n",
    "\n",
    "        return likelihood\n",
    "\n",
    "    def get_sentiment(self, text: str, max_length: int = 512) -> str:\n",
    "        \"\"\"\n",
    "        MODIFICA: sentiment of a text. If it is longer of max_ length token, segment it into chunks\n",
    "        \"\"\"\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        if len(tokens) > max_length:\n",
    "            chunks = [\n",
    "                self.tokenizer.convert_tokens_to_string(tokens[i:i+max_length])\n",
    "                for i in range(0, len(tokens), max_length)\n",
    "            ]\n",
    "            sentiments = []\n",
    "            for chunk in chunks:\n",
    "                result = self.sentiment_analyzer(chunk, truncation=True)[0]\n",
    "                sentiments.append(result['label'])\n",
    "            sentiment = max(set(sentiments), key=sentiments.count)\n",
    "        else:\n",
    "            sentiment = self.sentiment_analyzer(text, truncation=True)[0]['label']\n",
    "        return sentiment\n",
    "\n",
    "    def compute_sentiment_bonus(self, sources: List[str], candidates: List[str]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        MODIFICA: Compute sentiment bonus based on the aggregated sentiment\n",
    "        \"\"\"\n",
    "        bonus_list = []\n",
    "        for s_text, c_text in zip(sources, candidates):\n",
    "            s_sentiment = self.get_sentiment(s_text)\n",
    "            c_sentiment = self.get_sentiment(c_text)\n",
    "            if s_sentiment == c_sentiment:\n",
    "                bonus_list.append(1.0)\n",
    "            else:\n",
    "                bonus_list.append(-1.0)\n",
    "        return torch.tensor(bonus_list).to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "    def score(self, x: List[str], y: List[str], **kwargs):\n",
    "        \"\"\"\n",
    "        MODIFICA: Comine the likelihood with the sentiment bonus\n",
    "        \"\"\"\n",
    "        base_score = self.compute_conditionned_likelihood(x, y, **kwargs)\n",
    "        sentiment_bonus = self.compute_sentiment_bonus(x, y)\n",
    "        return base_score + self.sentiment_weight * sentiment_bonus\n",
    "\n",
    "    def likelihood_matrix(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :return: likelihood matrix : (num_source_texts, num_candidates),\n",
    "        dove likelihood[i, j] è la likelihood del candidato j per il source text i.\n",
    "        \"\"\"\n",
    "        likelihood_matrix = torch.zeros(\n",
    "            (len(self.source_texts), len(self.candidates))\n",
    "        ).to(self.device)\n",
    "\n",
    "        pairs = []\n",
    "        for i, source_text in enumerate(self.source_texts):\n",
    "            for j, candidate in enumerate(self.candidates):\n",
    "                pairs.append((i, j, source_text, candidate))\n",
    "\n",
    "        # split batch pairs\n",
    "        batches = [\n",
    "            pairs[i: i + self.batch_size]\n",
    "            for i in range(0, len(pairs), self.batch_size)\n",
    "        ]\n",
    "\n",
    "        for batch in tqdm(batches):\n",
    "            batch_sources = [pair[2] for pair in batch]\n",
    "            batch_candidates = [pair[3] for pair in batch]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                likelihoods = self.score(batch_sources, batch_candidates, mean=True)\n",
    "\n",
    "            for k, (i, j, _, _) in enumerate(batch):\n",
    "                likelihood_matrix[i, j] = likelihoods[k].detach()\n",
    "\n",
    "        return likelihood_matrix\n",
    "\n",
    "    @cache\n",
    "    def S(self, t):\n",
    "        if t == 0:\n",
    "            return self.initial_speaker_probas\n",
    "        else:\n",
    "            listener = self.L(t - 1)\n",
    "            prod = listener * self.rationality\n",
    "            return torch.log_softmax(prod, dim=-1)\n",
    "\n",
    "    @cache\n",
    "    def L(self, t):\n",
    "        speaker = self.S(t)\n",
    "        return torch.log_softmax(speaker, dim=-2)\n",
    "\n",
    "    def mk_listener_dataframe(self, t):\n",
    "        self.initial_speaker_probas = self.likelihood_matrix()\n",
    "\n",
    "        initial_listener_probas = self.L(0)\n",
    "\n",
    "        uniform_distribution_over_source_texts = torch.ones_like(\n",
    "            initial_listener_probas\n",
    "        ) / len(self.source_texts)\n",
    "\n",
    "        initital_consensuality_score = (\n",
    "                torch.exp(initial_listener_probas)\n",
    "                * (initial_listener_probas - torch.log(uniform_distribution_over_source_texts))\n",
    "        ).sum(0).cpu().numpy()\n",
    "\n",
    "        initital_consensuality_score = pd.Series(initital_consensuality_score, index=self.candidates)\n",
    "\n",
    "        initial_listener_probas = initial_listener_probas.cpu().numpy()\n",
    "        initial_listener_probas = pd.DataFrame(initial_listener_probas)\n",
    "        initial_listener_probas.index = self.source_texts\n",
    "        initial_listener_probas.columns = self.candidates\n",
    "\n",
    "        initial_speaker_probas = self.S(0).cpu().numpy()\n",
    "        initial_speaker_probas = pd.DataFrame(initial_speaker_probas)\n",
    "        initial_speaker_probas.index = self.source_texts\n",
    "        initial_speaker_probas.columns = self.candidates\n",
    "\n",
    "        listener_df = pd.DataFrame(self.L(t).cpu().numpy())\n",
    "        consensuality_scores = (\n",
    "                torch.exp(self.L(t))\n",
    "                * (self.L(t) - torch.log(uniform_distribution_over_source_texts))\n",
    "        ).sum(0).cpu().numpy()\n",
    "        consensuality_scores = pd.Series(consensuality_scores, index=self.candidates)\n",
    "\n",
    "        S_mat = self.S(t).cpu().numpy()\n",
    "        speaker_df = pd.DataFrame(S_mat)\n",
    "\n",
    "        listener_df.index = self.source_texts\n",
    "        speaker_df.index = self.source_texts\n",
    "        listener_df.columns = self.candidates\n",
    "        speaker_df.columns = self.candidates\n",
    "\n",
    "        return listener_df, speaker_df, initial_listener_probas, initial_speaker_probas, initital_consensuality_score, consensuality_scores\n",
    "\n",
    "    def rerank(self, t=1):\n",
    "        \"\"\"\n",
    "        Return the best summary (secondo RSA) per source text.\n",
    "        \"\"\"\n",
    "        (\n",
    "            listener_df,\n",
    "            speaker_df,\n",
    "            initial_listener_proba,\n",
    "            initial_speaker_proba,\n",
    "            initital_consensuality_score,\n",
    "            consensuality_scores,\n",
    "        ) = self.mk_listener_dataframe(t=t)\n",
    "        best_rsa = speaker_df.idxmax(axis=1).values\n",
    "        best_base = initial_listener_proba.idxmax(axis=1).values\n",
    "\n",
    "        return (\n",
    "            best_rsa,\n",
    "            best_base,\n",
    "            speaker_df,\n",
    "            listener_df,\n",
    "            initial_listener_proba,\n",
    "            initial_speaker_proba,\n",
    "            initital_consensuality_score,\n",
    "            consensuality_scores,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:37:19.202153Z",
     "iopub.status.busy": "2025-02-14T11:37:19.201832Z",
     "iopub.status.idle": "2025-02-14T11:38:00.586771Z",
     "shell.execute_reply": "2025-02-14T11:38:00.585928Z",
     "shell.execute_reply.started": "2025-02-14T11:37:19.202128Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "Using 2 GPUs!\n",
      "using a dataset with 5 articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31602811fa614473bfdf8879dc6e2f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaec40a2818c40a1968095ccf2b68ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9ce89d1f664ddfa910350146464350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b120d6812243aebd01cf6d6db8368d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:02<00:09,  2.31s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:03<00:05,  1.78s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:04<00:03,  1.55s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:05<00:01,  1.25s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\u001b[A\n",
      " 20%|██        | 1/5 [00:10<00:42, 10.69s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.54s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.47s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:14<00:19,  6.38s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:03,  1.13it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.06s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.28s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:19<00:12,  6.17s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.49s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:03<00:03,  1.53s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.51s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.31s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:25<00:05,  5.91s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:05,  1.31s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.15s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:31<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Summaries generated succesfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>best_base</th>\n",
       "      <th>speaker_df</th>\n",
       "      <th>listener_df</th>\n",
       "      <th>initial_listener</th>\n",
       "      <th>language_model_proba_df</th>\n",
       "      <th>initial_consensuality_scores</th>\n",
       "      <th>consensuality_scores</th>\n",
       "      <th>gold</th>\n",
       "      <th>rationality</th>\n",
       "      <th>text_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1jnyXXJx,)</td>\n",
       "      <td>[This paper proposes a regularizer that is cla...</td>\n",
       "      <td>[This paper proposes a regularizer that is cla...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>The paper proposes a method that helps escape ...</td>\n",
       "      <td>The paper proposes a method that helps escape ...</td>\n",
       "      <td>The paper proposes a method for accelerating o...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=BJO-BuT1g,)</td>\n",
       "      <td>[This paper introduces an elegant method to tr...</td>\n",
       "      <td>[Paper addresses problem of efficient neural s...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>It is done by learning a smaller set of parame...</td>\n",
       "      <td>It is done by learning a smaller set of parame...</td>\n",
       "      <td>The reviewers (two of whom stated maximum conf...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=BkCPyXm1l,)</td>\n",
       "      <td>[Aims to tackle neural network regularization ...</td>\n",
       "      <td>[Aims to tackle neural network regularization ...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>The authors introduced a regularization scheme...</td>\n",
       "      <td>The authors introduced a regularization scheme...</td>\n",
       "      <td>The reviewers unanimously recommend rejection.</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=S1HEBe_Jl,)</td>\n",
       "      <td>[The submission proposes to modify the typical...</td>\n",
       "      <td>[The submission proposes to modify the typical...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>The submission proposes to modify the typical ...</td>\n",
       "      <td>The submission proposes to modify the typical ...</td>\n",
       "      <td>Interesting paper but not over the accept bar.</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=S1J0E-71l,)</td>\n",
       "      <td>[Author's paper proposes to use surprisal-driv...</td>\n",
       "      <td>[Author's paper proposes to use surprisal-driv...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>Review of a new paper on how to use surprising...</td>\n",
       "      <td>Review of a new paper on how to use surprising...</td>\n",
       "      <td>Based on the feedback, I'm going to be rejecti...</td>\n",
       "      <td>3</td>\n",
       "      <td>index                                     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1jnyXXJx,)   \n",
       "1  (https://openreview.net/forum?id=BJO-BuT1g,)   \n",
       "2  (https://openreview.net/forum?id=BkCPyXm1l,)   \n",
       "3  (https://openreview.net/forum?id=S1HEBe_Jl,)   \n",
       "4  (https://openreview.net/forum?id=S1J0E-71l,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  [This paper proposes a regularizer that is cla...   \n",
       "1  [This paper introduces an elegant method to tr...   \n",
       "2  [Aims to tackle neural network regularization ...   \n",
       "3  [The submission proposes to modify the typical...   \n",
       "4  [Author's paper proposes to use surprisal-driv...   \n",
       "\n",
       "                                           best_base  \\\n",
       "0  [This paper proposes a regularizer that is cla...   \n",
       "1  [Paper addresses problem of efficient neural s...   \n",
       "2  [Aims to tackle neural network regularization ...   \n",
       "3  [The submission proposes to modify the typical...   \n",
       "4  [Author's paper proposes to use surprisal-driv...   \n",
       "\n",
       "                                          speaker_df  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                                         listener_df  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                                    initial_listener  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                             language_model_proba_df  \\\n",
       "0                                                ...   \n",
       "1                                                ...   \n",
       "2                                                ...   \n",
       "3                                                ...   \n",
       "4                                                ...   \n",
       "\n",
       "                        initial_consensuality_scores  \\\n",
       "0  The paper proposes a method that helps escape ...   \n",
       "1  It is done by learning a smaller set of parame...   \n",
       "2  The authors introduced a regularization scheme...   \n",
       "3  The submission proposes to modify the typical ...   \n",
       "4  Review of a new paper on how to use surprising...   \n",
       "\n",
       "                                consensuality_scores  \\\n",
       "0  The paper proposes a method that helps escape ...   \n",
       "1  It is done by learning a smaller set of parame...   \n",
       "2  The authors introduced a regularization scheme...   \n",
       "3  The submission proposes to modify the typical ...   \n",
       "4  Review of a new paper on how to use surprising...   \n",
       "\n",
       "                                                gold  rationality  \\\n",
       "0  The paper proposes a method for accelerating o...            3   \n",
       "1  The reviewers (two of whom stated maximum conf...            3   \n",
       "2     The reviewers unanimously recommend rejection.            3   \n",
       "3     Interesting paper but not over the accept bar.            3   \n",
       "4  Based on the feedback, I'm going to be rejecti...            3   \n",
       "\n",
       "                                     text_candidates  \n",
       "0      index                                     ...  \n",
       "1       index                                    ...  \n",
       "2      index                                     ...  \n",
       "3       index                                    ...  \n",
       "4      index                                     ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1jnyXXJx,)</td>\n",
       "      <td>[This paper proposes a regularizer that is cla...</td>\n",
       "      <td>The paper proposes a method for accelerating o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=BJO-BuT1g,)</td>\n",
       "      <td>[This paper introduces an elegant method to tr...</td>\n",
       "      <td>The reviewers (two of whom stated maximum conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=BkCPyXm1l,)</td>\n",
       "      <td>[Aims to tackle neural network regularization ...</td>\n",
       "      <td>The reviewers unanimously recommend rejection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=S1HEBe_Jl,)</td>\n",
       "      <td>[The submission proposes to modify the typical...</td>\n",
       "      <td>Interesting paper but not over the accept bar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=S1J0E-71l,)</td>\n",
       "      <td>[Author's paper proposes to use surprisal-driv...</td>\n",
       "      <td>Based on the feedback, I'm going to be rejecti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1jnyXXJx,)   \n",
       "1  (https://openreview.net/forum?id=BJO-BuT1g,)   \n",
       "2  (https://openreview.net/forum?id=BkCPyXm1l,)   \n",
       "3  (https://openreview.net/forum?id=S1HEBe_Jl,)   \n",
       "4  (https://openreview.net/forum?id=S1J0E-71l,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  [This paper proposes a regularizer that is cla...   \n",
       "1  [This paper introduces an elegant method to tr...   \n",
       "2  [Aims to tackle neural network regularization ...   \n",
       "3  [The submission proposes to modify the typical...   \n",
       "4  [Author's paper proposes to use surprisal-driv...   \n",
       "\n",
       "                                                gold  \n",
       "0  The paper proposes a method for accelerating o...  \n",
       "1  The reviewers (two of whom stated maximum conf...  \n",
       "2     The reviewers unanimously recommend rejection.  \n",
       "3     Interesting paper but not over the accept bar.  \n",
       "4  Based on the feedback, I'm going to be rejecti...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_rsa(summaries: pd.DataFrame, model, tokenizer, device):\n",
    "    results = []\n",
    "    for name, group in tqdm(summaries.groupby([\"id\"])):\n",
    "        rsa_reranker = RSAReranking(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            device=device,\n",
    "            candidates=group.summary.unique().tolist(),\n",
    "            source_texts=group.text.unique().tolist(),\n",
    "            batch_size=16,\n",
    "            rationality=3,\n",
    "            sentiment_weight=1.0  \n",
    "        )\n",
    "        \n",
    "        (\n",
    "            best_rsa,\n",
    "            best_base,\n",
    "            speaker_df,\n",
    "            listener_df,\n",
    "            initial_listener,\n",
    "            language_model_proba_df,\n",
    "            initial_consensuality_scores,\n",
    "            consensuality_scores,\n",
    "        ) = rsa_reranker.rerank(t=2)\n",
    "\n",
    "        gold = group['gold'].tolist()[0]\n",
    "        \n",
    "        best_rsa_filtered = filter_best_rsa_by_sentiment(best_rsa, gold, rsa_reranker)\n",
    "        \n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": name,\n",
    "                \"best_rsa\": best_rsa_filtered,  \n",
    "                \"best_base\": best_base,  \n",
    "                \"speaker_df\": speaker_df,\n",
    "                \"listener_df\": listener_df,\n",
    "                \"initial_listener\": initial_listener,\n",
    "                \"language_model_proba_df\": language_model_proba_df,\n",
    "                \"initial_consensuality_scores\": initial_consensuality_scores,\n",
    "                \"consensuality_scores\": consensuality_scores,\n",
    "                \"gold\": gold,\n",
    "                \"rationality\": 3, \n",
    "                \"text_candidates\": group\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# download model\n",
    "model_name = \"google/pegasus-arxiv\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"using {device} device\")\n",
    "\n",
    "# load the model and the tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "if \"pegasus\" in model_name:\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "output_path = \"../output/quality/\"\n",
    "# load the summaries\n",
    "summaries = parse_summaries(df_dataset)\n",
    "n_articles = 5\n",
    "selected_articles = list(summaries.groupby(\"id\").count().index[:n_articles])\n",
    "mask = [summaries[\"id\"][i] in selected_articles for i in range(len(summaries))]\n",
    "selected_summaries = summaries[mask]\n",
    "assert len(selected_summaries.groupby(\"id\").count()) == n_articles, \"Error in selecting articles!\"\n",
    "print(f\"using a dataset with {len(selected_summaries.groupby('id').count())} articles\")\n",
    "\n",
    "results = compute_rsa(selected_summaries, model, tokenizer, device)\n",
    "\n",
    "results = {\"results\": results}\n",
    "results[\"metadata/reranking_model\"] = model_name\n",
    "results[\"metadata/rsa_iterations\"] = 3\n",
    "\n",
    "print(\"Best Summaries generated succesfully!\")\n",
    "\n",
    "# save dataframe with base summaries\n",
    "all_base_df = pd.DataFrame(results[\"results\"])\n",
    "display(all_base_df)\n",
    "base_df = all_base_df.loc[:, [\"id\", \"best_rsa\", \"gold\"]]\n",
    "display(base_df)\n",
    "base_df.to_csv(f\"{output_path}base_glimpse_{year}_{n_articles}samples.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:39:44.856285Z",
     "iopub.status.busy": "2025-02-14T11:39:44.855971Z",
     "iopub.status.idle": "2025-02-14T11:39:45.034855Z",
     "shell.execute_reply": "2025-02-14T11:39:45.034102Z",
     "shell.execute_reply.started": "2025-02-14T11:39:44.856259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Glimpse Scores\n",
      "     rouge1    rouge2    rougeL  rougeLsum\n",
      "0  0.410714  0.126126  0.205357   0.205357\n",
      "1  0.166667  0.000000  0.111111   0.111111\n",
      "2  0.025641  0.000000  0.025641   0.025641\n",
      "3  0.062992  0.000000  0.062992   0.062992\n",
      "4  0.260536  0.038610  0.130268   0.130268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rouge1       0.185310\n",
       "rouge2       0.032947\n",
       "rougeL       0.107074\n",
       "rougeLsum    0.107074\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input base_df.astype(\"str\") to get base scores, new_df to get improved ones\n",
    "metrics = evaluate_rouge(base_df.astype(\"str\"))\n",
    "df = pd.DataFrame.from_dict(metrics)\n",
    "# scores for the base model\n",
    "print(\"Base Glimpse Scores\")\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bartbert Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T11:41:19.799690Z",
     "iopub.status.busy": "2025-02-14T11:41:19.799283Z",
     "iopub.status.idle": "2025-02-14T11:41:28.550407Z",
     "shell.execute_reply": "2025-02-14T11:41:28.549625Z",
     "shell.execute_reply.started": "2025-02-14T11:41:19.799663Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_rsa</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(https://openreview.net/forum?id=B1jnyXXJx,)</td>\n",
       "      <td>[This paper proposes a regularizer that is cla...</td>\n",
       "      <td>The paper proposes a method for accelerating o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(https://openreview.net/forum?id=BJO-BuT1g,)</td>\n",
       "      <td>[This paper introduces an elegant method to tr...</td>\n",
       "      <td>The reviewers (two of whom stated maximum conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(https://openreview.net/forum?id=BkCPyXm1l,)</td>\n",
       "      <td>[Aims to tackle neural network regularization ...</td>\n",
       "      <td>The reviewers unanimously recommend rejection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(https://openreview.net/forum?id=S1HEBe_Jl,)</td>\n",
       "      <td>[The submission proposes to modify the typical...</td>\n",
       "      <td>Interesting paper but not over the accept bar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(https://openreview.net/forum?id=S1J0E-71l,)</td>\n",
       "      <td>[Author's paper proposes to use surprisal-driv...</td>\n",
       "      <td>Based on the feedback, I'm going to be rejecti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0  (https://openreview.net/forum?id=B1jnyXXJx,)   \n",
       "1  (https://openreview.net/forum?id=BJO-BuT1g,)   \n",
       "2  (https://openreview.net/forum?id=BkCPyXm1l,)   \n",
       "3  (https://openreview.net/forum?id=S1HEBe_Jl,)   \n",
       "4  (https://openreview.net/forum?id=S1J0E-71l,)   \n",
       "\n",
       "                                            best_rsa  \\\n",
       "0  [This paper proposes a regularizer that is cla...   \n",
       "1  [This paper introduces an elegant method to tr...   \n",
       "2  [Aims to tackle neural network regularization ...   \n",
       "3  [The submission proposes to modify the typical...   \n",
       "4  [Author's paper proposes to use surprisal-driv...   \n",
       "\n",
       "                                                gold  \n",
       "0  The paper proposes a method for accelerating o...  \n",
       "1  The reviewers (two of whom stated maximum conf...  \n",
       "2     The reviewers unanimously recommend rejection.  \n",
       "3     Interesting paper but not over the accept bar.  \n",
       "4  Based on the feedback, I'm going to be rejecti...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c02edf8485d41ecbd0fe183ab818390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57d4c797f9641f2be45a826d474bb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcaa1da88de424c94e0a6a46752575d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d77c14640e46beb3790f05bcc19f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a19e5745ced4983af7a36517d1d3d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41754043ad284b989f28011788d5ea10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BERTScore\n",
      "0   0.852712\n",
      "1   0.828757\n",
      "2   0.822575\n",
      "3   0.814051\n",
      "4   0.823560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTScore    0.828331\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(base_df)\n",
    "metrics = evaluate_bartbert(base_df.astype(\"str\"))\n",
    "# make a dataframe with the metric\n",
    "df = pd.DataFrame(metrics)\n",
    "# base model bartbert scores\n",
    "print(df)\n",
    "df.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6558301,
     "sourceId": 10597484,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6614693,
     "sourceId": 10678162,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6655621,
     "sourceId": 10734523,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
