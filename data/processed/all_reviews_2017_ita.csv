,id,paper_title,abstract,reviewer,review,rating,conf_rev,metareview,conf_meta,recommendation
0,https://openreview.net/forum?id=r1rhWnZkg,Prodotto di Hadamard per Pooling Bilineare a Bassa Rango,"I modelli bilineari forniscono rappresentazioni ricche rispetto ai modelli lineari. Sono stati applicati in vari compiti di visione, come il riconoscimento di oggetti, la segmentazione e il visual question-answering, ottenendo prestazioni all'avanguardia grazie alle rappresentazioni espanse. Tuttavia, le rappresentazioni bilineari tendono a essere ad alta dimensionalità, limitando l'applicabilità a compiti computazionalmente complessi. Proponiamo un pooling bilineare a bassa rango che utilizza il prodotto di Hadamard per un meccanismo di attenzione efficiente nell'apprendimento multimodale. Dimostriamo che il nostro modello supera il pooling bilineare compatto nei compiti di visual question-answering, ottenendo risultati all'avanguardia sul dataset VQA e mostrando una migliore parsimonia.",10,"Riassunto: Il paper presenta un pooling bilineare a bassa rango che utilizza il prodotto di Hadamard (comunemente noto come moltiplicazione elemento per elemento). Il paper implementa il pooling bilineare a bassa rango su un modello esistente (Kim et al., 2016b) e costruisce un modello per il Visual Question Answering (VQA) che supera lo stato dell'arte attuale dello 0,42%. Il paper presenta vari studi di ablazione sul nuovo modello VQA sviluppato.----------------Punti di forza:----------------1. Il paper fornisce nuove intuizioni sull'operazione di moltiplicazione elemento per elemento, precedentemente utilizzata nella letteratura VQA (come Antol et al., ICCV 2015) senza spiegazioni sul perché dovrebbe funzionare. ----------------2. Il paper presenta un nuovo modello per il compito di VQA che supera lo stato dell'arte attuale dello 0,42%. Tuttavia, ho dubbi sulla significatività statistica del miglioramento delle prestazioni (vedi punti di debolezza sotto).----------------3. Le varie scelte progettuali effettuate nello sviluppo del modello sono state verificate sperimentalmente. ----------------Punti di debolezza/Suggerimenti:----------------1. Quando gli autori hanno confrontato esplicitamente (mantenendo invariata l'architettura del modello) il pooling bilineare a bassa rango con il pooling bilineare compatto, hanno scoperto che il primo ottiene prestazioni peggiori. Pertanto, non è stato possibile verificare sperimentalmente che il pooling bilineare a bassa rango sia migliore del pooling bilineare compatto (almeno per il compito di VQA).----------------2. Gli autori sostengono che il pooling bilineare a bassa rango utilizza il 25% di parametri in meno rispetto al pooling bilineare compatto. Potrebbero spiegare in che modo la riduzione del numero di parametri aiuta sperimentalmente? Il tempo di addestramento del modello si riduce significativamente? È possibile addestrare il modello con meno dati? ----------------3. Uno dei contributi del paper è che il modello proposto supera lo stato dell'arte attuale nel VQA dello 0,42%. Tuttavia, sono scettico sul fatto che questo miglioramento sia statisticamente significativo.----------------4. Vorrei che gli autori menzionassero esplicitamente le differenze tra MRN, MARN e MLB. Non è molto chiaro leggendo il paper.----------------5. Nella didascalia della Tabella 1, correggere la seguente espressione: “have not” -> “have no” ----------------Riassunto della recensione: Apprezzo le intuizioni fornite sul pooling bilineare a bassa rango mediante il prodotto di Hadamard (moltiplicazione elemento per elemento) presentate nel paper. Tuttavia, non è stato dimostrato che il pooling bilineare a bassa rango porti a prestazioni migliori rispetto al pooling bilineare compatto. Questo metodo riduce il numero di parametri, ma non è chiaro quanto ciò aiuti sperimentalmente. Per essere più convincente, vorrei che gli autori fornissero una giustificazione sperimentale del motivo per cui il pooling bilineare a bassa rango è migliore rispetto ad altre forme di pooling.","7: Buon paper, accettare",3: Il revisore è abbastanza sicuro che la valutazione sia corretta,"Il comitato di programma apprezza la risposta degli autori alle preoccupazioni sollevate nelle recensioni. Sebbene ci siano alcune criticità che gli autori sono fortemente incoraggiati a risolvere nella versione finale del paper, nel complesso il lavoro presenta contributi che meritano di essere presentati all'ICLR.",3: Il revisore è abbastanza sicuro che la valutazione sia corretta,Accettato (Poster)
0,https://openreview.net/forum?id=r1rhWnZkg,Prodotto di Hadamard per Pooling Bilineare a Bassa Rango,"I modelli bilineari forniscono rappresentazioni ricche rispetto ai modelli lineari. Sono stati applicati in vari compiti di visione, come il riconoscimento di oggetti, la segmentazione e il visual question-answering, ottenendo prestazioni all'avanguardia grazie alle rappresentazioni espanse. Tuttavia, le rappresentazioni bilineari tendono a essere ad alta dimensionalità, limitando l'applicabilità a compiti computazionalmente complessi. Proponiamo un pooling bilineare a bassa rango che utilizza il prodotto di Hadamard per un meccanismo di attenzione efficiente nell'apprendimento multimodale. Dimostriamo che il nostro modello supera il pooling bilineare compatto nei compiti di visual question-answering, ottenendo risultati all'avanguardia sul dataset VQA e mostrando una migliore parsimonia.",21,"I risultati sul compito di VQA sono buoni per questo modello semplice, e lo studio di ablazione nella tabella 1 fornisce alcune intuizioni su ciò che è importante. ----------------Mancano alcune spiegazioni sull'incorporazione del linguaggio e sull'importanza di decidere la dimensione dell'incorporazione e la dimensione finale dell'output, che equivale a decidere la dimensione proiettata nel modello bilineare compatto. Poiché il principale contributo del--------paper sembra essere una prestazione leggermente migliore con una riduzione abbastanza grande dei parametri rispetto al modello bilineare compatto, si dovrebbe dire qualcosa sulla scelta di questi iperparametri. Se si aumentano le dimensioni incorporate e di output per uguagliare i parametri del modello bilineare compatto, sono possibili ulteriori guadagni? Come viene codificata la domanda? L'ordine delle parole viene preservato in questa codifica? Il modello bilineare compatto confrontato nella tabella 1 menziona GloVe, il modello proposto utilizza lo stesso? Il significato dell'attenzione visiva in questo modello, insieme al numero di glimpses, dovrebbe essere collegato all'incorporazione della frase: quindi ora stiamo guardando particolari componenti spaziali quando quella parte della frase viene codificata, e poi impiliamo secondo la tua equazione 9?",6: Leggermente sopra la soglia di accettazione,3: Il revisore è abbastanza sicuro che la valutazione sia corretta,"Il comitato di programma apprezza la risposta degli autori alle preoccupazioni sollevate nelle recensioni. Sebbene ci siano alcune criticità che gli autori sono fortemente incoraggiati a risolvere nella versione finale del paper, nel complesso il lavoro presenta contributi che meritano di essere presentati all'ICLR.",3: Il revisore è abbastanza sicuro che la valutazione sia corretta,Accettato (Poster)
0,https://openreview.net/forum?id=r1rhWnZkg,Prodotto di Hadamard per il Pooling Bilineare a Bassa Rango,"I modelli bilineari forniscono rappresentazioni ricche rispetto ai modelli lineari. Sono stati applicati in vari compiti visivi, come il riconoscimento di oggetti, la segmentazione e il visual question-answering, ottenendo prestazioni all'avanguardia grazie alle rappresentazioni espanse. Tuttavia, le rappresentazioni bilineari tendono ad essere ad alta dimensionalità, limitando l'applicabilità a compiti computazionalmente complessi. Proponiamo un pooling bilineare a bassa rango utilizzando il prodotto di Hadamard per un meccanismo di attenzione efficiente nell'apprendimento multimodale. Dimostriamo che il nostro modello supera il pooling bilineare compatto nei compiti di visual question-answering, ottenendo risultati all'avanguardia sul dataset VQA, con una migliore parsimonia.",25,"Questo lavoro propone di approssimare il pooling bilineare (prodotto esterno) con una formulazione che utilizza il Prodotto di Hadamard (prodotto elemento per elemento). --------Questa formulazione è valutata sul compito di visual question answering (VQA) insieme a diverse varianti del modello.----------------Punti di forza:--------1. L'articolo discute come il prodotto di Hadamard può essere utilizzato per approssimare il prodotto esterno completo.--------2. L'articolo fornisce un'ampia valutazione sperimentale di altri aspetti del modello per il VQA.--------3. Il modello completo ottiene un leggero miglioramento rispetto allo stato dell'arte precedente nella sfida VQA, che è di grandi dimensioni e impegnativa.----------------Punti deboli:--------1. Novità: L'articolo presenta solo una nuova “interpretazione” del prodotto di Hadamard, che è già stato ampiamente utilizzato per il pooling, incluso per il VQA.--------2. Valutazione sperimentale:--------2.1. Manca un confronto sperimentale diretto con MCB. Sebbene il modello valutato sia simile a Fukui et al., sono state apportate diverse altre modifiche, tra cui codifica delle domande (GRU vs. LSTM), normalizzazione (tanh vs. L2 vs. nessuna). La piccola differenza nelle prestazioni (0,44% nella Tabella 1) potrebbe facilmente essere attribuita a queste differenze.--------2.2. Manca un confronto sperimentale con il prodotto esterno completo (ad esempio, per una dimensione inferiore). Rimane poco chiaro quanto sia buona l'approssimazione proposta per il prodotto esterno completo. Sebbene sia presentato un confronto con MCB, questo sembra insufficiente poiché MCB è un modello molto diverso.--------2.3. Uno dei parametri iper più importanti per il Prodotto di Hadamard sembra essere la dimensione dell'incorporamento a dimensione inferiore d. Quale effetto ha la sua variazione?--------2.4. Confronto con altre strategie di pooling, ad esempio somma elemento per elemento invece di prodotto elemento per elemento.--------3. Non viene presentata alcuna analisi teorica o proprietà dell'approssimazione.--------4. L'articolo sembra essere generale all'inizio, ma il vantaggio del prodotto di Hadamard è mostrato solo sperimentalmente sul dataset VQA.--------5. Lavori correlati: Il confronto con i lavori correlati nell'appendice dovrebbe essere almeno menzionato nell'articolo principale, anche se i dettagli sono nel supplemento.------------------------Minori--------- Non è chiaro perché sia citato Lu et al., 2015 invece del documento pubblicato da Antol et al.--------- Sezione 2, prima frase: “every pairs” -> “every pair”------------------------Sintesi:--------Sebbene l'articolo fornisca una nuova miglior prestazione e un'interpretazione interessante del prodotto di Hadamard, per essere un articolo forte, è necessaria un'analisi teorica più approfondita delle proprietà di questa approssimazione o una corrispondente valutazione sperimentale. È un po' sfortunato che la maggior parte della valutazione sperimentale non riguardi la principale affermazione dell'articolo (il prodotto di Hadamard) ma aspetti non correlati che sono importanti per ottenere alte prestazioni nella sfida VQA.----------------Per essere più convincente, vorrei vedere i seguenti esperimenti --------- Confronto con il prodotto esterno nello stesso modello--------- Confronto con MCB nello stesso modello--------- Confronto con somma elemento per elemento invece di prodotto elemento per elemento--------- Uno dei parametri iper più importanti per il Prodotto di Hadamard sembra essere la dimensione dell'incorporamento a dimensione inferiore d. Quale effetto ha la sua variazione?","7: Buon articolo, accettare",5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,"Il comitato del programma apprezza la risposta degli autori alle preoccupazioni sollevate nelle revisioni. Sebbene vi siano alcune criticità che gli autori sono fortemente incoraggiati a risolvere nella versione finale dell'articolo, nel complesso il lavoro presenta contributi degni di essere presentati a ICLR.",3: Il revisore è abbastanza sicuro che la valutazione sia corretta,Accettare (Poster)
0,https://openreview.net/forum?id=S1J0E-71l,Feedback Basato su Sorpresa nelle Reti Ricorrenti,"Le reti neurali ricorrenti sono ampiamente utilizzate per la previsione di dati temporali. La loro struttura intrinsecamente profonda feedforward consente di apprendere complessi schemi sequenziali. Si ritiene che un feedback dall'alto verso il basso possa essere un ingrediente mancante importante, che in teoria potrebbe aiutare a disambiguare schemi simili in base a un contesto più ampio. In questo articolo, introduciamo reti ricorrenti basate sulla sorpresa, che tengono conto delle informazioni sugli errori passati quando effettuano nuove previsioni. Ciò viene ottenuto monitorando continuamente la discrepanza tra le previsioni più recenti e le osservazioni reali. Inoltre, dimostriamo che il nostro modello supera altri approcci stocastici e completamente deterministici nel compito di previsione a livello di carattere su enwik8, raggiungendo 1,37 BPC.",7,"Sintesi:--------Questo articolo propone di utilizzare il feedback basato sulla sorpresa per addestrare reti neurali ricorrenti, in cui si utilizza l'errore di previsione del passo successivo della rete come input alla rete stessa. Gli autori hanno mostrato un risultato su compiti di modellazione del linguaggio.----------------Contributi:--------L'introduzione del feedback basato sulla sorpresa, che consiste semplicemente nel reintrodurre gli errori del modello dai passi temporali precedenti.----------------Domande:--------Un punto che non è completamente chiaro nell'articolo è se siano state utilizzate le etichette di verità a terra nel set di test per la parte di feedback sulla sorpresa del modello? Presumo che gli autori lo facciano, poiché affermano di usare l'errore di previsione errata come input aggiuntivo.----------------Critiche:--------L'articolo è scritto molto male, gli autori dovrebbero riconsiderare l'organizzazione del testo.--------La maggior parte delle equazioni presentate nell'articolo, relative a BPTT, non sono necessarie nel testo principale e potrebbero essere spostate in Appendice.--------La giustificazione non è abbastanza convincente.--------I risultati sperimentali sono insufficienti, vengono forniti solo risultati su un singolo dataset.--------Sebbene gli autori affermino di aver ottenuto lo stato dell'arte su enwiki8, ci sono altri articoli, come HyperNetworks, che hanno ottenuto risultati migliori (1,34) rispetto a quello raggiunto. Questa affermazione è errata.--------Il modello richiede le etichette di verità a terra per il set di test, tuttavia, questa assunzione limita fortemente l'applicazione di questa tecnica a un insieme molto ristretto di applicazioni (escludendo di fatto la maggior parte dei compiti di modellazione del linguaggio condizionale).----------------Revisione di alto livello:--------    Pro: --------        - Una modifica semplice del modello che sembra migliorare i risultati ed è un cambiamento interessante.----------------    Contro:--------       - Gli autori devono utilizzare le etichette del set di test.--------       - La scrittura dell'articolo è scarsa.--------       - Gli autori assumono di avere accesso alle etichette di verità a terra durante il test.--------       - I risultati sperimentali sono insufficienti.",4: Ok ma non abbastanza buono - rifiuto,4: Il revisore è fiducioso ma non assolutamente certo che la valutazione sia corretta,"Sulla base del feedback, rifiuterò l'articolo per i seguenti motivi:  1. I risultati non sono lo stato dell'arte come riportato.  2. Non ci sono veri esperimenti, solo esperimenti superficiali sui dati del premio Hutter.  3. La scrittura è molto scarsa.    Tuttavia, solo per fare l'avvocato del diavolo, ai revisori vorrei far notare che sono d'accordo con l'autore sul fatto che la valutazione dinamica non sia equivalente a questo metodo. I pesi non vengono modificati in questo modello, per quanto posso vedere, per il set di test. La sorpresa è solo un input aggiuntivo al modello. Penso che i revisori siano rimasti perplessi dal fatto che, durante il test, la sequenza effettiva debba essere nota. Sebbene questo possa essere problematico per la modellazione generativa, non vedo perché dovrebbe essere un problema per la modellazione del linguaggio, dove l'obiettivo del modello è solo fornire una probabilità logaritmica per valutare quanto sia buona una sequenza di testo. Molto prima che la modellazione del linguaggio iniziasse a essere utilizzata per generare testo, questo era il motivo principale per cui veniva usata, ad esempio nel riconoscimento vocale, nella correzione ortografica, ecc.",4: Il revisore è fiducioso ma non assolutamente certo che la valutazione sia corretta,Rifiutare
0,https://openreview.net/forum?id=S1J0E-71l,Feedback Basato su Sorpresa nelle Reti Ricorrenti,"Le reti neurali ricorrenti sono ampiamente utilizzate per la previsione di dati temporali. La loro struttura intrinsecamente profonda feedforward consente di apprendere complessi schemi sequenziali. Si ritiene che un feedback dall'alto verso il basso possa essere un ingrediente mancante importante, che in teoria potrebbe aiutare a disambiguare schemi simili in base a un contesto più ampio. In questo articolo, introduciamo reti ricorrenti basate sulla sorpresa, che tengono conto delle informazioni sugli errori passati quando effettuano nuove previsioni. Ciò viene ottenuto monitorando continuamente la discrepanza tra le previsioni più recenti e le osservazioni reali. Inoltre, dimostriamo che il nostro modello supera altri approcci stocastici e completamente deterministici nel compito di previsione a livello di carattere su enwik8, raggiungendo 1,37 BPC.",10,"Questo articolo propone di usare il segnale di errore precedente dello strato di output come input aggiuntivo alla funzione di aggiornamento ricorrente per migliorare il potere di modellazione di un sistema dinamico come le RNN. -----------------Questo articolo fa un'assunzione errata: le informazioni sulle etichette di test non sono fornite nella maggior parte delle applicazioni reali, eccetto in alcune applicazioni. Ciò significa che il compito di modellazione del linguaggio, che è l'unico esperimento di questo articolo, potrebbe non essere il compito giusto per testare questo approccio. Inoltre, confrontare con modelli che non usano il segnale di errore del test durante l'inferenza non è corretto. Non possiamo semplicemente dire che le informazioni sulle etichette di test vengono osservate, questo vale solo per i problemi di predizione online. -----------------L'esperimento è stato condotto su un solo dataset, riportando un risultato allo stato dell'arte, ma purtroppo questo non è vero. Ci sono già più di quattro articoli che riportano numeri migliori rispetto a quello riportato in questo compito, tuttavia l'autore non li ha citati. Capisco che questo articolo sia uscito prima degli altri, ma il manoscritto dovrebbe essere aggiornato prima della decisione finale. -----------------La dimensione del modello è ancora mancante e senza questa informazione è difficile giudicare il contributo del trucco proposto.",3: Rifiuto chiaro,5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,"Sulla base del feedback, rifiuterò l'articolo per i seguenti motivi:  1. I risultati non sono allo stato dell'arte come riportato.  2. Nessun vero esperimento se non esperimenti superficiali sui dati del premio Hutter.  3. La scrittura è molto scarsa. Tuttavia, solo per fare l'avvocato del diavolo, ai revisori vorrei far notare che sono d'accordo con l'autore sul fatto che la valutazione dinamica non sia equivalente a questo metodo. I pesi non vengono cambiati in questo modello, per quanto posso vedere, per il set di test. La sorpresa è solo un input aggiuntivo al modello. Penso che i revisori siano rimasti perplessi dal fatto che, durante il test, la sequenza effettiva debba essere nota. Sebbene questo possa essere problematico per la modellazione generativa, non vedo perché dovrebbe essere un problema per la modellazione del linguaggio, dove l'obiettivo del modello è solo fornire una log prob per valutare quanto sia buona una sequenza di testo. Molto prima che la modellazione del linguaggio iniziasse a essere utilizzata per generare testo, questo era il motivo principale per cui veniva usata, ad esempio nel riconoscimento vocale, nella correzione ortografica, ecc..",4: Il revisore è fiducioso ma non assolutamente certo che la valutazione sia corretta,Rifiutare
0,https://openreview.net/forum?id=S1J0E-71l,Feedback Basato su Sorpresa nelle Reti Ricorrenti,"Le reti neurali ricorrenti sono ampiamente utilizzate per la previsione di dati temporali. La loro struttura intrinsecamente profonda feedforward consente di apprendere complessi schemi sequenziali. Si ritiene che un feedback dall'alto verso il basso possa essere un ingrediente mancante importante, che in teoria potrebbe aiutare a disambiguare schemi simili in base a un contesto più ampio. In questo articolo, introduciamo reti ricorrenti basate sulla sorpresa, che tengono conto delle informazioni sugli errori passati quando effettuano nuove previsioni. Ciò viene ottenuto monitorando continuamente la discrepanza tra le previsioni più recenti e le osservazioni reali. Inoltre, dimostriamo che il nostro modello supera altri approcci stocastici e completamente deterministici nel compito di previsione a livello di carattere su enwik8, raggiungendo 1,37 BPC.",15,"Questo articolo propone di sfruttare la ""sorpresa"" come segnale dall'alto verso il basso nelle RNN. Più specificamente, l'autore usa l'errore corrispondente alla previsione precedente come input aggiuntivo al passo temporale corrente in una LSTM. -----------------L'idea generale del feedback basato sulla sorpresa è interessante per i compiti di previsione online. È un'idea abbastanza semplice che sembra portare a miglioramenti significativi. Tuttavia, l'articolo nella sua forma attuale ha alcuni difetti importanti. ----------------- In generale, la scrittura dell'articolo potrebbe essere migliorata. In particolare, la sezione 2.4 e 2.5 è composta principalmente dalle equazioni della propagazione in avanti e all'indietro del feedback RNN e del feedback LSTM. Tuttavia, l'autore non fornisce alcuna analisi insieme a queste equazioni. Non è quindi chiaro quale intuizione l'autore cerchi di esprimere in queste sezioni. Inoltre, il feedback RNN non è stato valutato nella sezione sperimentale, quindi non è chiaro perché il feedback RNN venga descritto. ----------------- La valutazione sperimentale è limitata. È stato esplorato solo un dataset, enwik8. Penso che sia necessario provare l'idea su altri dataset per vedere se il feedback LSTM porta a miglioramenti consistenti. -------- Inoltre, l'autore afferma di ottenere risultati allo stato dell'arte su enwik8, ma Hypernetwork, già citato nell'articolo, ottiene risultati migliori (1,34 BPC, tabella 4 nell'articolo su Hypernetworks). ----------------- L'autore confronta solo con metodi che non utilizzano l'errore di previsione dell'ultimo passo come segnale extra. Sostengo che un confronto con la valutazione dinamica sarebbe più equo. -------- Il feedback LSTM usa l'errore di previsione come input aggiuntivo nella propagazione in avanti, mentre la valutazione dinamica lo retropropaga attraverso la rete e modifica i pesi di conseguenza. Inoltre, non propagano l'errore di previsione nello stesso modo, ma entrambi sfruttano informazioni supervisionate ""extra"" attraverso gli errori di previsione. ------------------------In sintesi: --------Pro: --------- Idea interessante --------- Sembra migliorare le performance --------Contro: --------- Scrittura dell'articolo --------- Valutazione debole (solo un dataset) --------- Confronto solo con approcci che non usano il segnale di errore dell'ultimo passo",3: Rifiuto chiaro,5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,"Sulla base del feedback, rifiuterò l'articolo per i seguenti motivi:  1. I risultati non sono allo stato dell'arte come riportato.  2. Nessun vero esperimento se non esperimenti superficiali sui dati del premio Hutter.  3. La scrittura è molto scarsa. Tuttavia, solo per fare l'avvocato del diavolo, ai revisori vorrei far notare che sono d'accordo con l'autore sul fatto che la valutazione dinamica non sia equivalente a questo metodo. I pesi non vengono cambiati in questo modello, per quanto posso vedere, per il set di test. La sorpresa è solo un input aggiuntivo al modello. Penso che i revisori siano rimasti perplessi dal fatto che, durante il test, la sequenza effettiva debba essere nota. Sebbene questo possa essere problematico per la modellazione generativa, non vedo perché dovrebbe essere un problema per la modellazione del linguaggio, dove l'obiettivo del modello è solo fornire una log prob per valutare quanto sia buona una sequenza di testo. Molto prima che la modellazione del linguaggio iniziasse a essere utilizzata per generare testo, questo era il motivo principale per cui veniva usata, ad esempio nel riconoscimento vocale, nella correzione ortografica, ecc..",4: Il revisore è fiducioso ma non assolutamente certo che la valutazione sia corretta,Rifiutare
0,https://openreview.net/forum?id=BkCPyXm1l,Regolarizzazione Softtarget: Una Tecnica Efficace per Ridurre l'Overfitting nelle Reti Neurali,"Le reti neurali profonde sono modelli di apprendimento con una capacità molto alta e quindi soggetti all'overfitting. Molte tecniche di regolarizzazione, come Dropout, DropConnect e weight decay, cercano di risolvere il problema dell'overfitting riducendo la capacità dei rispettivi modelli (Srivastava et al., 2014), (Wan et al., 2013), (Krogh & Hertz, 1992). In questo articolo presentiamo una nuova forma di regolarizzazione che guida il problema di apprendimento in modo da ridurre l'overfitting senza sacrificare la capacità del modello. Gli errori che i modelli commettono nelle fasi iniziali dell'addestramento contengono informazioni sul problema di apprendimento. Regolando le etichette dell'epoca di addestramento corrente tramite una media ponderata delle etichette reali e una media esponenziale dei soft-target passati, abbiamo ottenuto uno schema di regolarizzazione potente quanto il Dropout senza necessariamente ridurre la capacità del modello e semplificando la complessità del problema di apprendimento. La regolarizzazione SoftTarget si è dimostrata uno strumento efficace in diverse architetture di reti neurali.",6,"L'articolo ha introdotto uno schema di regolarizzazione attraverso soft-target, che vengono prodotti mescolando le etichette vere e dure con la previsione del modello corrente. Un metodo molto simile è stato proposto nella Sezione 6 di (Hinton et al. 2016, Distilling the Knowledge in a Neural Network). ----------------Pro: --------+ Analisi completa sulla somiglianza tra co-etichetta. ----------------Contro: --------- Baseline deboli. Non sono sicuro che gli autori abbiano trovato i migliori iperparametri nei loro esperimenti. Ho appena addestrato un modello MNIST completamente connesso a 5 strati con 512 unità nascoste senza alcuna regolarizzazione e ho ottenuto un'accuratezza di 0,986 usando Adam e l'inizializzazione He, mentre l'articolo riporta 0,981 per un'architettura simile. --------- Gli autori non sono riusciti a proporre un'idea nuova. È molto simile a (Hinton et al. 2016). Probabilmente non è sufficiente per l'ICLR.",4: Ok ma non abbastanza buono - rifiuto,5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,"I revisori raccomandano unanimemente il rifiuto.",5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,Rifiutare
0,https://openreview.net/forum?id=BkCPyXm1l,Regolarizzazione Softtarget: Una Tecnica Efficace per Ridurre l'Overfitting nelle Reti Neurali,"Le reti neurali profonde sono modelli di apprendimento con una capacità molto alta e quindi soggetti all'overfitting. Molte tecniche di regolarizzazione, come Dropout, DropConnect e weight decay, cercano di risolvere il problema dell'overfitting riducendo la capacità dei rispettivi modelli (Srivastava et al., 2014), (Wan et al., 2013), (Krogh & Hertz, 1992). In questo articolo presentiamo una nuova forma di regolarizzazione che guida il problema di apprendimento in modo da ridurre l'overfitting senza sacrificare la capacità del modello. Gli errori che i modelli commettono nelle fasi iniziali dell'addestramento contengono informazioni sul problema di apprendimento. Regolando le etichette dell'epoca di addestramento corrente tramite una media ponderata delle etichette reali e una media esponenziale dei soft-target passati, abbiamo ottenuto uno schema di regolarizzazione potente quanto il Dropout senza necessariamente ridurre la capacità del modello e semplificando la complessità del problema di apprendimento. La regolarizzazione SoftTarget si è dimostrata uno strumento efficace in diverse architetture di reti neurali.",11,"Ispirato dall'analisi dell'effetto della somiglianza tra co-etichetta (Hinton et al., 2015), questo articolo propone una regolarizzazione soft-target che addestra iterativamente la rete utilizzando la media ponderata della media mobile esponenziale delle etichette passate e delle etichette dure come argomento di perdita. Gli autori affermano che questo previene la scomparsa della somiglianza tra co-etichetta dopo l'addestramento iniziale e offre una regolarizzazione competitiva rispetto al dropout senza sacrificare la capacità della rete. ----------------Per fare un confronto equo con il dropout, il dropout dovrebbe essere sintonizzato con attenzione. Mostrare che funziona meglio della regolarizzazione dropout per alcuni valori particolari di dropout (Tabella 2) non dimostra un vantaggio convincente. È possibile che il dropout funzioni meglio dopo una corretta sintonizzazione con la cross-validation. ----------------Le architetture baseline utilizzate negli esperimenti non appartengono ai metodi recenti dello stato dell'arte, producendo quindi una precisione significativamente inferiore. Sembra anche che l'impostazione dell'esperimento non preveda alcuna augmentation dei dati, i risultati potrebbero anche cambiare con l'augmentation. Non è chiaro perché il numero di epoche sia impostato su un numero ridotto come 100 senza eseguire dei test di convergenza. Pertanto, la significatività del metodo non è dimostrata in modo convincente nello studio empirico. ----------------Le somiglianze tra co-etichetta potrebbero essere calcolate utilizzando i risultati del softmax sull'ultimo strato invece di utilizzare le etichette previste. Il vantaggio rispetto al dropout non è chiaro nella Figura 4, il dropout è impostato su 0,2 senza alcuna cross-validation. ------------------------La regolarizzazione forzando i passaggi di addestramento a mantenere la somiglianza tra le co-etichetta è un'idea interessante ma non molto nuova e i risultati non sono significativi. ----------------Pro: --------- Fornisce un'indagine sulla regolarizzazione della somiglianza tra co-etichetta durante l'addestramento ----------------Contro: --------I risultati empirici non supportano le affermazioni intuitive riguardo alla procedura proposta --------La versione iterativa può essere instabile nella pratica",3: Rifiuto chiaro,5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,"I revisori raccomandano unanimemente il rifiuto.",5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,Rifiutare
0,https://openreview.net/forum?id=BkCPyXm1l,Regolarizzazione Softtarget: Una Tecnica Efficace per Ridurre l'Overfitting nelle Reti Neurali,"Le reti neurali profonde sono modelli di apprendimento con una capacità molto alta e quindi soggetti all'overfitting. Molte tecniche di regolarizzazione, come Dropout, DropConnect e weight decay, cercano di risolvere il problema dell'overfitting riducendo la capacità dei rispettivi modelli (Srivastava et al., 2014), (Wan et al., 2013), (Krogh & Hertz, 1992). In questo articolo presentiamo una nuova forma di regolarizzazione che guida il problema di apprendimento in modo da ridurre l'overfitting senza sacrificare la capacità del modello. Gli errori che i modelli commettono nelle fasi iniziali dell'addestramento contengono informazioni sul problema di apprendimento. Regolando le etichette dell'epoca di addestramento corrente tramite una media ponderata delle etichette reali e una media esponenziale dei soft-target passati, abbiamo ottenuto uno schema di regolarizzazione potente quanto il Dropout senza necessariamente ridurre la capacità del modello e semplificando la complessità del problema di apprendimento. La regolarizzazione SoftTarget si è dimostrata uno strumento efficace in diverse architetture di reti neurali.",17,"Questo manoscritto cerca di affrontare la regolarizzazione delle reti neurali mescolando la distribuzione dell'etichetta con le previsioni del modello stesso. In questo senso è simile nello spirito a scheduled sampling (Bengio et al) e SEARN (Daume et al) DAgger (Ross et al) che considerano una miscela ""roll-in"" della distribuzione dell'etichetta e del modello durante l'addestramento. È stato chiarito nelle domande pre-review che queste etichette vengono generate online piuttosto che da una distribuzione ritardata, il che rende il pseudocodice dell'algoritmo un po' fuorviante se lo capisco correttamente. ----------------Si tratta di un miglioramento incrementale dell'idea di etichettatura morbida che è stata recentemente rivisitata, quindi la novità non è particolarmente alta. L'autore fa notare che la somiglianza tra co-etichetta è meglio preservata da questo metodo, ma non segue che questo sia causale rispetto alla regolarizzazione; una baseline naturale sarebbe una distribuzione dell'etichetta morbida fissa, così come una in cui la morbidezza/temperatura della distribuzione dell'etichetta viene gradualmente ridotta (come ci si aspetterebbe che faccia questo metodo man mano che il modello si avvicina alla riproduzione della distribuzione dell'etichetta). ----------------È un'idea interessante e in qualche modo attraente, ma non è chiaro che sia così utile. Le baseline di dropout per MNIST sembrano essere molto lontane dai risultati già presenti nella letteratura (Srivastava et al 2014 ottiene l'1,06% con un MLP 3x1024 con dropout e una semplice limitazione max norm; le baseline di dropout qui non superano l'1,3%, che è piuttosto alto secondo gli standard contemporanei sul task di permutazione invariabile), e i risultati per CIFAR10 sono molto lontani dallo stato dell'arte, rendendo difficile giudicare il contributo alla luce di altre innovazioni. Il benchmark più grande considerato è SVHN, dove le precisioni riportate sono davvero molto basse; SOTA per la performance di rete singola è stata meno della metà degli errori riportati per 3-4 anni. Non è chiaro quali conclusioni si possano trarre su come questo potrebbe aiutare (o addirittura danneggiare) in un setting meglio sintonizzato. ----------------Ho delle riserve sul trattamento dei dati, ossia riportare la perdita minima del test/la massima precisione del test invece di un metodo non distorto per la selezione del modello (come l'errore minimo del set di validazione, ad esempio). Correlato a ciò, non è stata considerata la potenzialità di regolarizzazione del fermo precoce su un set di validazione. Vedi, ad esempio, il protocollo in Goodfellow et al (2013).",4: Ok ma non abbastanza buono - rifiuto,5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,"I revisori raccomandano unanimemente il rifiuto.",5: Il revisore è assolutamente certo che la valutazione sia corretta ed è molto familiare con la letteratura pertinente,Rifiutare
0,https://openreview.net/forum?id=B1jnyXXJx,Charged Point Normalization: An Efficient Solution To The Saddle Point Problem,"Recentemente, il problema dei minimi locali nell'ottimizzazione non convessa di alta dimensione è stato messo in discussione e il problema dei punti sella è stato introdotto. Questo articolo introduce un tipo di normalizzazione dinamica che costringe il sistema a sfuggire ai punti sella. A differenza di altri algoritmi di fuga dai punti sella, non vengono utilizzate informazioni di secondo ordine, e il sistema può essere addestrato con qualsiasi tipo di gradiente discendente. Il sistema migliora drasticamente l'apprendimento in una gamma di reti neurali profonde su vari dataset rispetto alle reti neurali non CPN.",6,"Sommario:--------Questo articolo propone un regolarizzatore che si ritiene aiuti a sfuggire dai punti sella. Il metodo è ispirato dalla fisica, in modo tale che pensare al processo di ottimizzazione come se stesse spostando una particella carica positivamente sulla superficie di errore, la quale sarebbe respinta dai punti sella a causa del punto sella stesso che viene caricato positivamente. Gli autori dell'articolo mostrano risultati su diversi dataset.----------------Panoramica della recensione:--------    Pro:--------        - L'idea è molto interessante.--------        - La varietà di risultati su diversi dataset.--------    Contro:--------        - La giustificazione non è abbastanza solida.--------        - Il documento non è scritto molto bene.--------        - Gli esperimenti non sono abbastanza convincenti.----------------Critiche:----------------Mi è piaciuta l'idea e le intuizioni presentate nell'articolo. Tuttavia, penso che questo articolo non sia scritto molto bene. Ci sono alcune variabili introdotte nel paper e non spiegate adeguatamente, ad esempio in 2.3, gli autori iniziano a parlare di p senza introdurlo e definirlo correttamente. L'unico altro posto in cui appare prima è l'Equazione 6. Le equazioni necessitano di alcune modifiche, in particolare per migliorare il flusso dell'articolo, ad esempio introducendo tutte le variabili correttamente prima di utilizzarle.----------------L'Equazione 6 appare senza una spiegazione e giustificazione adeguata. Sarebbe necessario spiegare cosa significa correttamente, poiché penso che questa sia una delle equazioni più importanti in questo articolo. Un'analisi maggiore su cosa significa dal punto di vista dell'ottimizzazione sarebbe apprezzata.---------------- non è un parametro, è una funzione che ha il proprio iperparametro.----------------Sarebbe interessante riportare i risultati di validazione o test su alcuni compiti. Poiché questo metodo è introdotto come una funzione di costo aggiuntiva, sarebbe interessante anche il suo effetto sui risultati di validazione/test.--------Gli autori dovrebbero discutere di più su come hanno scelto gli iperparametri dei loro modelli. ----------------Le Figure 2 e 3 non aggiungono molto al documento e sono molto difficili da comprendere o trarre conclusioni. ----------------Ci sono molte figure sotto 3.4.2 senza etichette o didascalie. Alcune sono molto piccole e difficili da comprendere poiché le etichette sulle figure appaiono molto piccole e in qualche modo illeggibili.------------------------Una piccola domanda:----------------* Effettuate anche il backpropagation attraverso --------?",5: Leggermente sotto la soglia di accettazione,4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,"L'articolo propone un metodo per accelerare l'ottimizzazione vicino ai punti sella durante l'addestramento di reti neurali profonde. L'idea è quella di respingere il vettore dei parametri attuali da una media mobile dei parametri recenti. Il metodo proposto ha mostrato di ottimizzare più velocemente rispetto ad altri metodi su diversi dataset e architetture. L'autore presenta un'idea fresca nell'area dell'ottimizzazione stocastica per le reti neurali profonde. Tuttavia, l'articolo non sembra essere sopra la soglia di accettazione, a causa dei dubbi residui sulla completezza degli esperimenti. Invitiamo quindi questo articolo alla presentazione nella sezione Workshop.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Invita alla Track del Workshop
0,https://openreview.net/forum?id=B1jnyXXJx,Charged Point Normalization: An Efficient Solution To The Saddle Point Problem,"Recentemente, il problema dei minimi locali nell'ottimizzazione non convessa di alta dimensione è stato messo in discussione e il problema dei punti sella è stato introdotto. Questo articolo introduce un tipo di normalizzazione dinamica che costringe il sistema a sfuggire ai punti sella. A differenza di altri algoritmi di fuga dai punti sella, non vengono utilizzate informazioni di secondo ordine, e il sistema può essere addestrato con qualsiasi tipo di gradiente discendente. Il sistema migliora drasticamente l'apprendimento in una gamma di reti neurali profonde su vari dataset rispetto alle reti neurali non CPN.",9,"Questo articolo propone un metodo innovativo per accelerare l'ottimizzazione vicino ai punti sella. L'idea di base è quella di respingere il vettore dei parametri attuali da una media mobile dei parametri recenti. Questo metodo ha mostrato di ottimizzare più velocemente rispetto ad altri metodi su diversi dataset e architetture.----------------A prima vista, il metodo proposto sembra estremamente simile al momento. Sarebbe molto utile pensare a un diagramma chiaro che illustra come differisce dal momento e perché potrebbe essere migliore vicino a un punto sella. L'illustrazione di una migliore convergenza nell'esempio del punto sella giocattolo non è ciò che intendo qui—le comparazioni di velocità di ottimizzazione sono sempre difficili a causa dei numerosi dettagli e iperparametri coinvolti, quindi vederlo funzionare più velocemente in una specifica applicazione non è così utile come un diagramma concettuale che mostra un caso critico in cui CPN si comporterà in modo diverso—e chiaramente qualitativamente migliore—rispetto al momento.----------------Un altro modo per arrivare alla relazione con il momento sarebbe cercare una forma per R_t(f) che produca l'aggiornamento esatto del momento. Si potrebbe quindi confrontare questo con R_t(f) utilizzato in CPN.----------------La notazione eccessivamente generale etc dovrebbe essere eliminata—l'Equazione 8 è sufficiente.----------------I risultati teorici (Equazione 1 e Teorema 1) dovrebbero essere rimossi, sono irrilevanti fino a quando non viene specificata la densità congiunta.----------------Sperimentalmente, sarebbe utile standardizzare i risultati per consentire il confronto con altri metodi. Ad esempio, ricreare la Figura 4 di Dauphin et al., ma utilizzando il metodo CPN piuttosto che SFN, dimostrerebbe chiaramente che CPN può sfuggire a qualcosa che il momento non può.----------------Penso che l'idea sia potenzialmente molto valida, ma necessita di un confronto più rigoroso e una chiara relazione con il momento e altri lavori.",4: Ok ma non abbastanza buono - rifiuto,4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,"L'articolo propone un metodo per accelerare l'ottimizzazione vicino ai punti sella durante l'addestramento di reti neurali profonde. L'idea è quella di respingere il vettore dei parametri attuali da una media mobile dei parametri recenti. Il metodo proposto ha mostrato di ottimizzare più velocemente rispetto ad altri metodi su diversi dataset e architetture. L'autore presenta un'idea fresca nell'area dell'ottimizzazione stocastica per le reti neurali profonde. Tuttavia, l'articolo non sembra essere sopra la soglia di accettazione, a causa dei dubbi residui sulla completezza degli esperimenti. Invitiamo quindi questo articolo alla presentazione nella sezione Workshop.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Invita alla Track del Workshop
0,https://openreview.net/forum?id=B1jnyXXJx,Charged Point Normalization: An Efficient Solution To The Saddle Point Problem,"Recentemente, il problema dei minimi locali nell'ottimizzazione non convessa di alta dimensione è stato messo in discussione e il problema dei punti sella è stato introdotto. Questo articolo introduce un tipo di normalizzazione dinamica che costringe il sistema a sfuggire ai punti sella. A differenza di altri algoritmi di fuga dai punti sella, non vengono utilizzate informazioni di secondo ordine, e il sistema può essere addestrato con qualsiasi tipo di gradiente discendente. Il sistema migliora drasticamente l'apprendimento in una gamma di reti neurali profonde su vari dataset rispetto alle reti neurali non CPN.",13,"La direzione della ricerca intrapresa da questo articolo è di grande interesse. -------- Tuttavia, i risultati empirici non sono abbastanza buoni da compensare le debolezze dell'approccio proposto (vedi Sezione 6). -------- ""In tutto l'articolo la selezione degli iperparametri è stata mantenuta piuttosto semplice."" ma il termine di momento di CPN è impostato a 0,95 -------- e non a 0,9 come in tutti/i principali ottimizzatori con cui CPN è confrontato. Suppongo che l'effetto positivo di CPN (se presente) sia dovuto principalmente al suo termine di momento.",4: Ok ma non abbastanza buono - rifiuto,3: Il revisore è abbastanza sicuro che la valutazione sia corretta,"L'articolo propone un metodo per accelerare l'ottimizzazione vicino ai punti sella durante l'addestramento di reti neurali profonde. L'idea è quella di respingere il vettore dei parametri attuali da una media mobile dei parametri recenti. Il metodo proposto ha mostrato di ottimizzare più velocemente rispetto ad altri metodi su diversi dataset e architetture. L'autore presenta un'idea fresca nell'area dell'ottimizzazione stocastica per le reti neurali profonde. Tuttavia, l'articolo non sembra essere sopra la soglia di accettazione, a causa dei dubbi residui sulla completezza degli esperimenti. Invitiamo quindi questo articolo alla presentazione nella sezione Workshop.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Invita alla Track del Workshop
0,https://openreview.net/forum?id=S1vyujVye,Deep Unsupervised Learning Through Spatial Contrasting,"Le reti neurali convoluzionali hanno guadagnato una posizione di rilievo negli ultimi anni come modello con le migliori prestazioni per vari compiti visivi. Tuttavia, sono più adatte per l'apprendimento supervisionato da grandi quantità di dati etichettati. Sono stati fatti precedenti tentativi di utilizzare dati non etichettati per migliorare le prestazioni del modello applicando tecniche non supervisionate. Questi tentativi richiedono architetture e metodi di addestramento diversi. In questo lavoro presentiamo un nuovo approccio per l'addestramento non supervisionato delle reti convoluzionali basato sul contrasto tra regioni spaziali all'interno delle immagini. Questo criterio può essere utilizzato all'interno di reti neurali convenzionali e addestrato con tecniche standard come SGD e back-propagation, complementando così i metodi supervisionati.",6,"Questo articolo propone un obiettivo di addestramento non supervisionato basato sul contrasto dei patch per l'apprendimento della rappresentazione visiva tramite reti neurali profonde. In particolare, le rappresentazioni delle caratteristiche dei patch dalla stessa immagine sono incoraggiate ad essere più vicine rispetto a quelle di immagini diverse. I rapporti di distanza delle coppie di addestramento positive vengono ottimizzati. Il metodo proposto è empiricamente mostrato essere efficace come metodo di inizializzazione per l'addestramento supervisionato. ----------------Punti di forza:----------------- L'obiettivo di addestramento è ragionevole. In particolare, le caratteristiche di alto livello mostrano invarianza alla traduzione. ----------------- I metodi proposti sono efficaci per inizializzare le reti neurali per l'addestramento supervisionato su diversi dataset. ------------------------Punti di debolezza:----------------- I metodi sono tecnicamente simili alla “exemplar network” (Dosovitskiy 2015). Il ritaglio dei patch da una singola immagine può essere considerato come un tipo di data augmentation, paragonabile all'augmentation del campione positivo (l'esemplare) in (Dosovitskiy 2015). ----------------- L'articolo è sperimentalmente fuorviante.--------I risultati riportati in questo articolo si basano sul fine-tuning dell'intera rete con supervisione. Tuttavia, nella Tabella 2, i risultati delle exemplar convnets (Dosovitskiy 2015) provengono dall'apprendimento delle caratteristiche non supervisionato (la rete non viene fine-tuned con campioni etichettati, e solo un classificatore viene addestrato sulle caratteristiche). Pertanto, il confronto non è equo. Sospetto che le exemplar convnets (Dosovitskiy 2015) otterrebbero miglioramenti simili dal fine-tuning; quindi, senza tali confronti (comparazione diretta con e senza fine-tuning basata sulla stessa architettura eccetto per la loss), i risultati sperimentali non sono completamente convincenti. ----------------Per quanto riguarda il confronto con l'autoencoder “What-where” (Zhao et al, 2015), sarebbe interessante confrontarsi con esso in impostazioni su larga scala, come mostrato da Zhang et al, ICML 2016 (Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-Scale Image Classification). Allenare un AlexNet non è molto dispendioso in termini di tempo con le GPU più recenti (ad esempio, livello TITAN-X). ----------------Il metodo proposto sembra utile solo per le immagini naturali, dove i patch di una stessa immagine possono essere simili tra loro.",5: Marginalmente sotto la soglia di accettazione,4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,"L'articolo propone una formulazione per l'apprendimento non supervisionato delle ConvNets basato sulla distanza tra patch campionati dalla stessa e da immagini diverse. La novità del metodo è piuttosto limitata in quanto è simile a [Doersch et al. 2015] e [Dosovitsky et al. 2015]. La valutazione è stata eseguita solo su piccoli dataset, il che limita l'impatto potenziale del contributo.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Rifiuto
0,https://openreview.net/forum?id=S1vyujVye,Deep Unsupervised Learning Through Spatial Contrasting,"Le reti neurali convoluzionali hanno guadagnato una posizione di rilievo negli ultimi anni come modello con le migliori prestazioni per vari compiti visivi. Tuttavia, sono più adatte per l'apprendimento supervisionato da grandi quantità di dati etichettati. Sono stati fatti precedenti tentativi di utilizzare dati non etichettati per migliorare le prestazioni del modello applicando tecniche non supervisionate. Questi tentativi richiedono architetture e metodi di addestramento diversi. In questo lavoro presentiamo un nuovo approccio per l'addestramento non supervisionato delle reti convoluzionali basato sul contrasto tra regioni spaziali all'interno delle immagini. Questo criterio può essere utilizzato all'interno di reti neurali convenzionali e addestrato con tecniche standard come SGD e back-propagation, complementando così i metodi supervisionati.",10,"La perdita di auto-apprendimento proposta è formulata utilizzando un'architettura Siamese e incoraggia i patch della stessa immagine a trovarsi più vicini nello spazio delle caratteristiche rispetto a un patch contrastante preso da un'immagine diversa e casuale. La perdita è molto simile nello spirito a quella di Doersch et al. ICCV 2015 e Isola et al. ICLR 2016 workshop. Sembra che la perdita proposta sia in realtà una versione semplificata di Doersch et al. ICCV 2015 in quanto non fa uso dello spostamento spaziale, un segnale di auto-apprendimento liberamente disponibile nelle immagini naturali. Intuitivamente, sembra che il problema di auto-apprendimento posto da questo metodo sia più semplice, e quindi meno potente, rispetto a quello dei lavori precedenti. Mi piacerebbe vedere più discussioni sul confronto tra questi due approcci. Tuttavia, il metodo proposto sembra essere efficace nel raggiungere buoni risultati empirici utilizzando questa semplice loss. Tuttavia, dovrebbero essere forniti più dettagli sull'implementazione, come l'effetto delle dimensioni dei patch, la sovrapposizione tra i patch campionati, e qualsiasi altra misura importante adottata per evitare soluzioni banali.",6: Marginalmente sopra la soglia di accettazione,4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,"L'articolo propone una formulazione per l'apprendimento non supervisionato delle ConvNets basato sulla distanza tra patch campionati dalla stessa e da immagini diverse. La novità del metodo è piuttosto limitata in quanto è simile a [Doersch et al. 2015] e [Dosovitsky et al. 2015]. La valutazione è stata eseguita solo su piccoli dataset, il che limita l'impatto potenziale del contributo.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Rifiuto
0,https://openreview.net/forum?id=S1vyujVye,Deep Unsupervised Learning Through Spatial Contrasting,"Le reti neurali convoluzionali hanno guadagnato la loro posizione come il modello più performante per diversi compiti visivi. Tuttavia, sono maggiormente adatte all'apprendimento supervisionato da grandi quantità di dati etichettati. Sono stati fatti tentativi precedenti di utilizzare dati non etichettati per migliorare le prestazioni del modello applicando tecniche non supervisionate. Questi tentativi richiedono architetture e metodi di addestramento diversi. In questo lavoro presentiamo un nuovo approccio per l'addestramento non supervisionato delle reti convoluzionali basato sul contrasto tra regioni spaziali all'interno delle immagini. Questo criterio può essere impiegato all'interno di reti neurali convenzionali e addestrato utilizzando tecniche standard come SGD e retropropagazione, complementando così i metodi supervisionati.",14,"Questo lavoro presenta un nuovo modo di eseguire pre-addestramento non supervisionato in un contesto di reti neurali convoluzionali profonde (sebbene probabilmente applicabile anche alle reti completamente connesse). Il metodo è quello del ‘spatial constrasting’ ossia costruire triplette da frammenti delle immagini di input e imparare una rappresentazione che assegna un punteggio alto ai frammenti provenienti dalla stessa immagine e un punteggio basso per quelli provenienti da immagini diverse. Il metodo è abbastanza semplice che mi sorprende che nessuno ci abbia provato prima (almeno secondo i lavori precedenti nel sottomesso). Ecco alcuni commenti:------------------------L'uso di P(f_i^1 | f_i^2) nella sezione 4.1 è un po' strano. Potrebbe valere la pena definire matematicamente che tipo di probabilità gli autori intendono o semplicemente rimuovere quella parte (“probabilità” può essere sostituita con un'altra parola).----------------Mi piacerebbe sapere di più su come il metodo utilizza le "statistiche del batch" (fine della sezione 4.2) campionandole a meno che gli autori non intendano semplicemente che campionano tutte le possibili triple nel loro batch.----------------Il numero di frammenti campionati nell'Algoritmo 1 non dovrebbe essere un iperparametro piuttosto che essere solo 1? Gli autori hanno provato altri valori?----------------Penso che ci siano alcuni dettagli mancanti nel lavoro come la dimensione dei frammenti o se gli autori ci abbiano giocato (penso che questo sia un iperparametro importante).----------------I risultati STL sono abbastanza impressionanti ma CIFAR-10 forse non tanto. Per CIFAR mi aspetterei che si possa provare a pre-addestrare su ad esempio Imagenet + CIFAR per costruire una rappresentazione migliore. Gli autori hanno preso in considerazione questo?------------------------In generale questo è un lavoro interessante con alcune applicazioni evidenti e sembra relativamente semplice da implementare e provare. Penso che avrei voluto una maggiore comprensione di cosa impara effettivamente il spatial contrasting più studi empirici sugli effetti delle varie scelte di parametri (ad esempio la dimensione del frammento) e più tentativi di battere lo stato dell'arte (ad esempio CIFAR).","7: Buon lavoro, accettato",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,"Il lavoro propone una formulazione per l'apprendimento non supervisionato delle ConvNet basato sulla distanza tra frammenti campionati dalla stessa e da immagini diverse. La novità del metodo è piuttosto limitata poiché è simile a [Doersch et al. 2015] e [Dosovitsky et al. 2015]. La valutazione è stata effettuata solo su piccoli set di dati, il che limita l'impatto potenziale del contributo.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Rifiuto
0,https://openreview.net/forum?id=S1HEBe_Jl,Learning To Protect Communications With Adversarial Neural Cryptography,"Ci chiediamo se le reti neurali possano imparare a utilizzare chiavi segrete per proteggere le informazioni da altre reti neurali. In particolare, ci concentriamo sull'assicurare le proprietà di riservatezza in un sistema multi-agente, e le specifichiamo in termini di un avversario. Pertanto, un sistema potrebbe consistere in reti neurali chiamate Alice e Bob, e l'obiettivo è limitare ciò che una terza rete neurale chiamata Eve può apprendere ascoltando la comunicazione tra Alice e Bob. Non prescriviamo algoritmi crittografici specifici per queste reti neurali; invece, addestriamo il sistema in modo end-to-end e avversariale. Dimostriamo che le reti neurali possono imparare a eseguire forme di cifratura e decifratura, e anche come applicare queste operazioni selettivamente per soddisfare gli obiettivi di riservatezza.",6,"Il sottomesso propone di modificare leggermente l'architettura tipica dei GAN per includere i moduli ""encrypt"" (Alice) e ""decrypt"" (Bob) oltre a un modulo che cerca di decifrare il segnale senza una chiave (Eve). Tramite la trasmissione ripetuta dei segnali, il gioco avversariale è destinato a convergere verso un sistema in cui Alice e Bob possono comunicare in modo sicuro (o almeno una parte designata del segnale dovrebbe essere sicura), mentre un sofisticato Eve non può rompere il loro codice. Sono forniti esempi su dati di prova:--------""Come prova di concetto, abbiamo implementato le reti Alice, Bob ed Eve che prendono valori casuali di N-bit di testo in chiaro e chiavi e producono cifrature di valori in virgola mobile di N voci, per N = 16, 32 e 64. Sia i valori del testo in chiaro che della chiave sono distribuiti uniformemente.""----------------L'idea considerata qui è interessante. Se alcune, ma non necessariamente tutte, le informazioni devono essere sicure, i moduli possono imparare a cifrare e decifrare un segnale, mentre un avversario viene simultaneamente addestrato a cercare di rompere la cifratura. In questo modo, alcuni dati possono rimanere non cifrati, mentre la parte correlata con il segnale cifrato dovrà essere cifrata affinché Eve non possa prevedere la parte cifrata.----------------Mentre questa è una buona idea teorica, ci sono significativi ostacoli affinché questo sottomesso abbia un impatto pratico:--------1) I GAN e, dai grafici di convergenza, anche l'obiettivo considerato qui, sono piuttosto instabili da ottimizzare. Le uniche garanzie di privacy sono per un Eve che è convergente verso un avversario molto forte (più forte di un attacco dedicato nel tempo). Non vedo come si possano avere garanzie affidabili sulla sicurezza della trasmissione dei dati con l'approccio proposto, almeno l'articolo non delinea tale garanzia.--------2) I sistemi di crittografia a chiave pubblica sono facilmente disponibili, computazionalmente fattibili e applicati con successo quasi ovunque. Gli esempi di prova dati nell'articolo non mi convincono affatto che questo stia risolvendo un problema reale in questo momento. Forse un buon esempio emergerà nel prossimo futuro e questo lavoro si dimostrerà giustificato, ma finché non verrà mostrato tale esempio, l'approccio è più un interessante esperimento teorico.",5: Appena sotto la soglia di accettazione,4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,"Articolo interessante ma non sopra la soglia di accettazione.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Rifiuto
0,https://openreview.net/forum?id=S1HEBe_Jl,Learning To Protect Communications With Adversarial Neural Cryptography,"Ci chiediamo se le reti neurali possano imparare a utilizzare chiavi segrete per proteggere le informazioni da altre reti neurali. In particolare, ci concentriamo sull'assicurare le proprietà di riservatezza in un sistema multi-agente, e le specifichiamo in termini di un avversario. Pertanto, un sistema potrebbe consistere in reti neurali chiamate Alice e Bob, e l'obiettivo è limitare ciò che una terza rete neurale chiamata Eve può apprendere ascoltando la comunicazione tra Alice e Bob. Non prescriviamo algoritmi crittografici specifici per queste reti neurali; invece, addestriamo il sistema in modo end-to-end e avversariale. Dimostriamo che le reti neurali possono imparare a eseguire forme di cifratura e decifratura, e anche come applicare queste operazioni selettivamente per soddisfare gli obiettivi di riservatezza.",10,"Il lavoro riguarda una interessante applicazione dell'addestramento avversariale alla crittografia. Considera lo scenario standard di Alice, Eve e Bob, dove A e B mirano a scambiarsi messaggi condizionati da una chiave condivisa, mentre Eve non dovrebbe riuscire a crittografare il messaggio. Gli esperimenti sono stati effettuati in un compito di cifratura simmetrica semplice a 16 bit e in un'applicazione sulla privacy. I concetti, le idee e la letteratura precedente sono presentati in modo piuttosto chiaro e accurato.----------------L'unica preoccupazione principale che ho – e mi scuso con gli autori per non averlo sollevato prima - riguarda gli esperimenti nella sezione 3. In particolare, non capisco del tutto lo scenario. Il ragionamento sembra essere il seguente: dato un'informazione < A, B, C, D >, voglio fornire al pubblico il valore di D (ad esempio, film visti) senza rilasciare informazioni su C (ad esempio, il sesso). In questo scenario, Eve dovrebbe essere in grado di ricostruire D il più accuratamente possibile senza acquisire informazioni su C. Tuttavia, ciò che è descritto nella sezione 3 è che sia D che D-pubblico sono entrambi ricostruiti da Bob, ma perché Bob dovrebbe ricostruire quest'ultimo (non è pubblico, in particolare perché è autorizzato a ricostruire C, cosa che non viene testata qui)? Inoltre, Eve cerca solo di stimare C, il che rende lo scenario non diverso in alcun modo dallo scenario considerato nella sezione 2.----------------Ho altre due piccole preoccupazioni:----------------1) Come sollevato nel pre-revisore, Eve dovrebbe essere effettivamente più forte di Alice e Bob per poter compensare la chiave mancante. Gli autori hanno osservato di aver eseguito questi esperimenti e di aggiungere i risultati.----------------2) In qualsiasi caso di crittografia naturale mi aspetterei che la lunghezza della chiave fosse molto più corta della lunghezza del messaggio. Questo, tuttavia, potrebbe rendere lo scenario molto più facile per Eve (anche se dubito che i risultati cambieranno se la chiave è abbastanza lunga).----------------Mi piace l'applicazione creativa dell'addestramento avversariale a un dominio completamente diverso, e credo che potrebbe essere il punto di partenza per una direzione molto interessante nei sistemi crittografici o nelle applicazioni di privacy (anche se non è chiaro se le deboli garanzie degli approcci basati su reti neurali possano mai essere superate). Allo stesso tempo, l'applicazione nel contesto della privacy mi lascia piuttosto confuso, e l'esempio di crittografia simmetrica non è particolarmente forte. Mi piacerebbe se gli autori potessero affrontare la principale preoccupazione che ho sollevato, e sarò felice di aumentare il punteggio nel caso in cui questa confusione possa essere risolta.",6: Appena sopra la soglia di accettazione,3: Il revisore è abbastanza sicuro che la valutazione sia corretta,"Articolo interessante ma non sopra la soglia di accettazione.",4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Rifiuto
0,https://openreview.net/forum?id=S1HEBe_Jl,Learning To Protect Communications With Adversarial Neural Cryptography,"Ci chiediamo se le reti neurali possano imparare a utilizzare chiavi segrete per proteggere le informazioni da altre reti neurali. In particolare, ci concentriamo sull'assicurare le proprietà di riservatezza in un sistema multi-agente, e le specifichiamo in termini di un avversario. Pertanto, un sistema potrebbe consistere in reti neurali chiamate Alice e Bob, e l'obiettivo è limitare ciò che una terza rete neurale chiamata Eve può apprendere ascoltando la comunicazione tra Alice e Bob. Non prescriviamo algoritmi crittografici specifici per queste reti neurali; invece, addestriamo il sistema in modo end-to-end e avversariale. Dimostriamo che le reti neurali possono imparare a eseguire forme di cifratura e decifratura, e anche come applicare queste operazioni selettivamente per soddisfare gli obiettivi di riservatezza.",14,"Questo lavoro propone l'uso dei GAN per comunicazioni cifrate.----------------Nella sezione 2, gli autori propongono una rete neurale a 3 parti addestrata per codificare e decodificare i dati. Questo modello non ha alcun valore pratico se non per aprire la strada alla descrizione del modello successivo nella sezione 3: è decisamente peggiore di qualsiasi sistema crittografico provabile.----------------Nella sezione 3, gli autori progettano un compito in cui vogliono nascondere parte dei dati, che hanno campi correlati, mentre pubblicano il resto. Tuttavia, faccio fatica a pensare a un'applicazione in cui questo sistema sia migliore di una semplice decorrelazione dei dati e cifratura dei campi che si vogliono nascondere con un sistema crittografico provabile, mentre il resto viene pubblicato in chiaro.",4: Ok ma non abbastanza buono - rifiuto,"2: Il revisore è disposto a difendere la valutazione, ma è molto probabile che non abbia compreso alcune parti centrali del paper",Articolo interessante ma non sopra la soglia di accettazione.,4: Il revisore è sicuro ma non assolutamente certo che la valutazione sia corretta,Rifiuto